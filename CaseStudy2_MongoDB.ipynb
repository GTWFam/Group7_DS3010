{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/GTWFam/Group7_DS3010/blob/main/CaseStudy2_MongoDB.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IQZqJy0gY6Dl"
      },
      "source": [
        "# Case Study 2 : Putting Twitter Data into the Cloud\n",
        "\n",
        "Due Date: 2/15/2020, **BEFORE the beginning of class at 2:00pm EST**\n",
        "\n",
        "## **NOTE: There are *always* last minute issues submitting the case studies.  DO NOT WAIT UNTIL THE LAST MINUTE!**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JyNhpJN5Y6Dn"
      },
      "source": [
        "<a title=\"FabiÃ¡n Alexis [CC BY-SA (https://creativecommons.org/licenses/by-sa/3.0)]\" href=\"https://commons.wikimedia.org/wiki/File:Antu_mongodb.svg\"><img width=\"50\" alt=\"Antu mongodb\" src=\"https://upload.wikimedia.org/wikipedia/commons/thumb/f/f9/Antu_mongodb.svg/512px-Antu_mongodb.svg.png\"></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DhXEvLb5Y6Do"
      },
      "source": [
        "**TEAM Members:** Please EDIT this cell and add the names of all the team members in your team\n",
        "\n",
        "    Jacob Bissonette\n",
        "    Austin Franklin \n",
        "    Yuriy Kamenivskyy \n",
        "    Garrett McMerriman\n",
        "    Bill Hoang Pham"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IdtCbjp9Y6Do"
      },
      "source": [
        "**Don't forget!**\n",
        "* You will need to install the pymongo library to access MongoDB\n",
        " * pip install pymongo\n",
        "* You will also need to install dnspython to access the cloud version of MongoDB\n",
        " * pip install dnspython\n",
        "\n",
        "** NOTE **\n",
        "* **Please don't forget to save the notebook frequently when working in IPython Notebook, otherwise the changes you made can be lost**."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1R87hP_pY6Dq"
      },
      "source": [
        "# Problem 1 (20 points):  Get a cloud database account using MongoDB Atlas"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Q10TAFcOY6Dq"
      },
      "source": [
        "Get a free cloud hosted MongoDB database account at https://www.mongodb.com/atlas/database.  You will need to: \n",
        "\n",
        "* Create a database cluster using the MongoDB web interface\n",
        "* Get your MongoDB credentials\n",
        "* Create a document collection in MongoBD\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7dOckKukY6Ds"
      },
      "source": [
        "# Problem 2 (20 points):  Read Twitter data into your cloud MongoDB database"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-yQgleDnY6Ds"
      },
      "source": [
        "Gather Twitter data and upload it to your cloud database.  You will need to:\n",
        "\n",
        "* Get your cloubd MongoDB credentials using the MongoDB web interface\n",
        "* Insert those credentials into your Juypyter notebook using pymongo\n",
        "* Gather Twitter data as in Case Study 1\n",
        "* Upload your Twitter data to the MongoDB cloud document collection\n",
        "\n",
        "Note, to do you this question remember that you will need *two sets of credentials*\n",
        "\n",
        "* One set for the MongoDB Atlas database\n",
        "* One set for the Twitter developed API\n",
        "\n",
        "Of course, there are not the same!"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "! pip install pymongo\n",
        "! pip install dnspython\n"
      ],
      "metadata": {
        "id": "zHd0WyWXrT7g",
        "outputId": "253ffe66-1485-4251-c557-3c6b741d8d2f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: pymongo in /usr/local/lib/python3.7/dist-packages (4.0.1)\n",
            "Requirement already satisfied: dnspython in /usr/local/lib/python3.7/dist-packages (2.2.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "MO0paphxY6Dq",
        "outputId": "5c0a2aeb-acb6-4c7b-a621-8778da3a4cda",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "#----------------------------------------------\n",
        "# Your code starts here\n",
        "#   Please add comments or text cells in between to explain the general idea of each block of the code.\n",
        "#   Please feel free to add more cells below this cell if necessary\n",
        "import pymongo\n",
        "import json\n",
        "\n",
        "from google.colab import drive\n",
        "\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "data = {}\n",
        "    \n",
        "# Extracting the saved credentials from the drive\n",
        "with open('drive/MyDrive/ds3010_2022/credentials.txt', 'r') as f:\n",
        "    data = json.load(f)\n",
        "CONSUMER_KEY = data[\"consumer_key\"]\n",
        "CONSUMER_SECRET = data[\"consumer_secret\"]\n",
        "OAUTH_TOKEN = data[\"oauth_token\"]\n",
        "OAUTH_TOKEN_SECRET = data[\"oauth_token_secret\"]\n",
        "mongodb_url = data[\"mongodb_url\"]\n",
        "\n",
        "client = pymongo.MongoClient(mongodb_url)\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Getting the Database and Collection from MongoDB\n",
        "db = client['DS3010']\n",
        "coll = db['CS2']"
      ],
      "metadata": {
        "id": "w1p9Z5f3sctw"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "! pip install twitter"
      ],
      "metadata": {
        "id": "qD5dgzJlsTIC",
        "outputId": "c356231a-137c-4fa5-8fd2-1ff70d917c7a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: twitter in /usr/local/lib/python3.7/dist-packages (1.19.3)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "my4IUYVvY6Ds"
      },
      "outputs": [],
      "source": [
        "#----------------------------------------------\n",
        "# Your code starts here\n",
        "#   Please add comments or text cells in between to explain the general idea of each block of the code.\n",
        "#   Please feel free to add more cells below this cell if necessary\n",
        "import twitter\n",
        "\n",
        "# See https://dev.twitter.com/docs/auth/oauth for more information \n",
        "# on Twitter's OAuth implementation.\n",
        "\n",
        "auth = twitter.oauth.OAuth(OAUTH_TOKEN, OAUTH_TOKEN_SECRET,\n",
        "                           CONSUMER_KEY, CONSUMER_SECRET)\n",
        "\n",
        "twitter_api = twitter.Twitter(auth=auth)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "query = \"macbook pro 2021\"\n",
        "\n",
        "data = twitter_api.search.tweets(q=query, lang='en', count=100)\n",
        "\n",
        "min_id = data['statuses'][-1]['id']\n",
        "for i in range(7):\n",
        "    tweets = twitter_api.search.tweets(q=query, lang='en', max_id=min_id, count=100)\n",
        "    min_id = tweets['statuses'][-1]['id']\n",
        "    data['statuses'] += tweets['statuses']\n"
      ],
      "metadata": {
        "id": "8DgXTFziu12O"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "statuses = data['statuses']\n",
        "coll.drop()\n",
        "_ = coll.insert_many(statuses)"
      ],
      "metadata": {
        "id": "2ZdWGUR2vqZu"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ui6DxP0lY6Dt"
      },
      "source": [
        "# Problem 3 (20 points):  Use a regular expression to read a subset of your Tweets out of MongoDB"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "63qOpjc9Y6Dt"
      },
      "source": [
        "Use regular expressions to analyze properties of your data.  For example, you can \n",
        "\n",
        "* search for trends that have a large volume, \n",
        "* search for tweets with geotags, \n",
        "* search for tweets that can contain a certain string,\n",
        "* anything else you think might be useful for a product!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "id": "5W_39LCaY6Du",
        "outputId": "c893650c-5870-442e-f208-0d5e63f8abb5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Tech bro/sis, final year brethren, graphic designers, writers, anyone in need of a good laptop or money, this tweetâ¦ https://t.co/REQeY1t0YZ\n",
            "Clientâs MacBook Pro 14â 2021 model/16GB Ram/512GB SSD M1Pro chip - Ready 4 delivery/ More of this Still in stockâ¦ https://t.co/AzX70Jcqfh\n",
            "Nah!!! Apple is Goated for their User Experience\n",
            "\n",
            "Might fuck around and drop an extra $5K+ to pick up an iMac and uâ¦ https://t.co/22SciRqcZY\n",
            "This season, @xendfinance is giving out a brand new MacBook pro 2021, and a prize pool of $2,000, to 20 savers \n",
            "\n",
            "Toâ¦ https://t.co/8bqmdhSbYb\n",
            "New saving challenge:\n",
            "\n",
            "You save N3,000 every day from now till February 28th, and at the end, you win a MacBook Proâ¦ https://t.co/2YFPEiTmXY\n",
            "The battery life on the 2021 Macbook Pro is wild y'all... I've been using my computer for an hour &amp; it still says tâ¦ https://t.co/vtoMoLyDj5\n",
            "In the spirit of love &amp; financial responsibility, @xendfinance is giving out a BRAND NEW MacBook Pro 2021, and prizâ¦ https://t.co/YPXNlAV5sZ\n",
            "The 2021 MacBook pro is such a beautiful and powerful machine ð¥°\n",
            "\n",
            "AND @Xendfinance WANTS TO DASH YOU A BRAND NEW ONEâ¦ https://t.co/k9XnLj3KYa\n",
            "Clientâs MacBook Pro 13inch/512GB SSD/ 2021 model delivered / Thank u Signum Advocates 4 the orders\n",
            "\n",
            "Contact us forâ¦ https://t.co/6c2BasfiSX\n"
          ]
        }
      ],
      "source": [
        "#----------------------------------------------\n",
        "# Your code starts here\n",
        "#   Please add comments or text cells in between to explain the general idea of each block of the code.\n",
        "#   Please feel free to add more cells below this cell if necessary\n",
        "\n",
        "query = { \"favorite_count\": { \"$gt\": 20 } }\n",
        "cursor = coll.find(query)\n",
        "\n",
        "for tweet in cursor:\n",
        "    print(tweet['text'])"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### There are no tweets that has a geotag"
      ],
      "metadata": {
        "id": "yr-d93Db4iUX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "query2 = { \"geo\": { \"$ne\": None } }\n",
        "cursor = coll.find(query2)\n",
        "\n",
        "for tweet in cursor:\n",
        "    print(tweet['text'])"
      ],
      "metadata": {
        "id": "CPd_H_VX7lDD"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "query3 = { \"text\": { '$regex': '^.*cool.*$', '$options': 'si' } }\n",
        "cursor = coll.find(query3)\n",
        "\n",
        "for tweet in cursor:\n",
        "    print(tweet['text'])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zkvtx5Z242yQ",
        "outputId": "db407c2c-1f7a-48b8-fabd-9da932f59b06"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "TECOOL Custodia per 2021 MacBook Pro 14, MacBook Air/Pro 13, 13,5 Surface Laptop, 14â Huawei Matebook, ASUS Zenbookâ¦ https://t.co/H9wSWkPrpD\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "query4 = { \"text\": { '$regex': '^.*battery.*$', '$options': 'si' } }\n",
        "cursor = coll.find(query4)\n",
        "\n",
        "for tweet in cursor:\n",
        "    print(tweet['text'])"
      ],
      "metadata": {
        "id": "DGwFPOgWAOB7",
        "outputId": "ca77d0a0-2415-4fc5-d61a-6cd20ca57622",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The battery life on the 2021 Macbook Pro is wild y'all... I've been using my computer for an hour &amp; it still says tâ¦ https://t.co/vtoMoLyDj5\n",
            "RT @wccftech: Appleâs 2021 MacBook Pro Lasts 60% Longer Than the Best High-End Notebookâs Battery Timing, Claims Neâ¦ https://t.co/FuZ58FkCog\n",
            "RT @wccftech: Appleâs 2021 MacBook Pro Lasts 60% Longer Than the Best High-End Notebookâs Battery Timing, Claims New Test https://t.co/NFvBâ¦\n",
            "RT @wccftech: Appleâs 2021 MacBook Pro Lasts 60% Longer Than the Best High-End Notebookâs Battery Timing, Claims New Test https://t.co/NFvBâ¦\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "collapsed": true,
        "id": "n0iZmkh7Y6Du"
      },
      "source": [
        "# Problem 4 (20 points): Business question \n",
        "\n",
        "Run some additional experiments with your data to gain familiarity with the MongoDB.\n",
        "\n",
        "* Come up with a business question that Twitter data and MongoDB could help answer.\n",
        "* Decribe the business case.\n",
        "* How could MongoDB help a company to scale up its computation environment?"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Our business lies in helping entrepreneurs better understand their market using twitter data, prior to them making an investing decision. Our research model is flexible and can be used to research just about any topic.\n",
        "\n",
        "The model is the following: \n",
        "1. We determine the market's underserved needs by analyzing negative sentiment tweets related to the business of choice. After collecting all negative sentiment tweets, we determine the most frequently occuring words, and then search for tweets containing these words to get an idea of what the problem / underserved need may be.\n",
        "2. We determine the market's table stakesââ needs that are satisfied by all the other competitors, and thus have to be satisfied by us as wellââ to do this we follow an identical algorithm to problem 1, but now we query for tweets with a positive sentiment.\n",
        "3. We identify the creators of most liked and most retweeted positive tweets; and then look for overlapping accounts that they follow. These accounts will be our primary contacts for targeted advertisement of the new product.\n",
        "\n",
        "MongoDB helps us organize this data into different collection and use regular expressions to query data efficiently and accurately."
      ],
      "metadata": {
        "id": "X9QQ8ONpeJgh"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**1. Researching Negative attitude tweets. Pushing to a MongoDB dbs. Looking for most frequent words. Looking for tweets with a geotag to see if we can determine where did negative attitudes come from. Listing 10 sentences where each of the most frequent words occurs to get the idea of what people are unhappy about.**"
      ],
      "metadata": {
        "id": "pzjdfWPeYBkY"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "id": "Q_JRP_b5Y6Dv",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9dc8c347-5778-43b4-998f-b4b69dbe507b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "179\n"
          ]
        }
      ],
      "source": [
        "# Negative attitudes\n",
        "query1 = 'burger OR burgers :( -filter:retweets'\n",
        "\n",
        "data1 = twitter_api.search.tweets(q=query1, lang='en', count=100)\n",
        "\n",
        "min_id = data1['statuses'][-1]['id']\n",
        "for i in range(10):\n",
        "    tweets = twitter_api.search.tweets(q=query1, lang='en', max_id=min_id, count=100)\n",
        "    min_id = tweets['statuses'][-1]['id']\n",
        "    data1['statuses'] += tweets['statuses']\n",
        "\n",
        "statuses1 = data1['statuses']\n",
        "print(len(statuses1))\n",
        "coll_neg = db['cs2_coll_neg']\n",
        "# coll_neg.drop()\n",
        "# _ = coll_neg.insert_many(statuses1)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Similar to Case Study 1, looking at most common words\n",
        "\n",
        "import re\n",
        "exclude = ['rt', 'in', 'the', 'for','of', 'to', 'and', 'a', 'is', 'are', 'on', 'from', 'that', 'this', 'these', 'with', 'what', 'it', 'if', 'or', 'but', 'your', 'be', 'you', 'my', 'at', 'd', 'its', 'i', 'so', 'was', 'he', 'me', 'no', 'about']\n",
        "\n",
        "tweet_texts_neg = [ re.sub(r\"[^\\w\\s'#@]\", \"\", tweets['text']) for tweets in statuses1 ]\n",
        "print(tweet_texts_neg[0])\n",
        "words_neg = [ w for t in tweet_texts_neg for w in t.lower().split() ]\n",
        "words_neg = list(filter(lambda x: x not in exclude, words_neg))\n",
        "print(words_neg[1])"
      ],
      "metadata": {
        "id": "w6eMTHwBUqgT",
        "outputId": "3df8a1fc-f97f-4902-ec96-bc57e4163202",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "shadow dedede update Hammed burger \n",
            "dedede\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from prettytable import PrettyTable\n",
        "from collections import Counter\n",
        "\n",
        "c = Counter(words_neg)\n",
        "top_words_neg = c.most_common()[:10]\n",
        "print(top_words_neg) # top 10\n",
        "\n",
        "pt = PrettyTable(field_names=['Word', 'Count'])\n",
        "[ pt.add_row(kv) for kv in c.most_common()[:10] ]\n",
        "pt.align['Word'], pt.align['Count'] = 'l', 'r'\n",
        "print(pt)"
      ],
      "metadata": {
        "id": "G4TVsj3fVX5K",
        "outputId": "aef31fc3-5c00-451b-e6c8-7d3ee6f36294",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[('burger', 130), ('burgers', 28), ('like', 18), ('king', 18), ('want', 18), ('im', 17), ('dont', 15), ('had', 14), ('not', 12), ('have', 12)]\n",
            "+---------+-------+\n",
            "| Word    | Count |\n",
            "+---------+-------+\n",
            "| burger  |   130 |\n",
            "| burgers |    28 |\n",
            "| like    |    18 |\n",
            "| king    |    18 |\n",
            "| want    |    18 |\n",
            "| im      |    17 |\n",
            "| dont    |    15 |\n",
            "| had     |    14 |\n",
            "| not     |    12 |\n",
            "| have    |    12 |\n",
            "+---------+-------+\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Attempt to look for negative sentiment tweets with a geo-tag. Might give us an idea of where competitors fail or make bad burgers\n",
        "query_neg1 = { \"geo\": { '$ne': None } }\n",
        "cursor = coll_neg.find(query_neg1)\n",
        "\n",
        "for tweet in cursor:\n",
        "    print(tweet['text'])"
      ],
      "metadata": {
        "id": "djfhuFZISA1t"
      },
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Looking at tweets that have the most used words\n",
        "for combo in top_words_neg:\n",
        "    print(combo[0])\n",
        "    query = { \"text\": { '$regex': '^.* '+ combo[0] + ' .*$', '$options': 'si' } }\n",
        "    cursor = coll_neg.find(query)\n",
        "    i = 0\n",
        "    # Printing first 10 tweets\n",
        "    printed = []\n",
        "    for tweet in cursor:\n",
        "        # Filtering out the not useful and spamming data\n",
        "        if tweet['text'] in printed:\n",
        "            continue\n",
        "        if i >= 10:\n",
        "            break\n",
        "        print(tweet['text'], '\\n')\n",
        "        printed.append(tweet['text'])\n",
        "        i += 1\n",
        "\n",
        "    print(\"-\"*100)"
      ],
      "metadata": {
        "id": "YORgp_sIbIB0",
        "outputId": "ea96e8ea-80d3-4220-edfa-551f121bb243",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "burger\n",
            "P. Terryâs got rid of their hatch green chile burger :( \n",
            "\n",
            "I hate my bf rn, he ate my burger Iâve been saving all night bc I was drunk :( \n",
            "\n",
            "shadow dedede update! Hammed burger :( \n",
            "\n",
            "i had a burger yest :( https://t.co/JROObe7Bke \n",
            "\n",
            "hobi is eating a burger i want one too :( \n",
            "\n",
            "Wanted to try the @JackBox Heinz Dip and Crunch Bacon Cheeseburger tonight - ended up with a dry burger and no dipâ¦ https://t.co/D75PKV7ngh \n",
            "\n",
            "@Harry1T6 I LOVE Burger Priest, I would have got it instead but I just had it yesterday lmao. My go to is the Doublâ¦ https://t.co/V3s8EPmUZa \n",
            "\n",
            "Checking Etsy to see if anyone's made the burger shirt from the cover of Nona the Ninth yet. Can't find one. :( \n",
            "\n",
            "@bludsex burger king :( https://t.co/Rs1SFNwcxf \n",
            "\n",
            "til to melt vegan cheese on ur burger in the oven bc otherwise it will slide away :( \n",
            "\n",
            "----------------------------------------------------------------------------------------------------\n",
            "burgers\n",
            "@imnickintl I've mainly had their pasta and It was bad :( and the burgers ok! \n",
            "\n",
            "@kbbyhoon but I want to flip burgers :( \n",
            "\n",
            "Come on I need burgers I'm starving :( https://t.co/JKttxdNyr1 \n",
            "\n",
            "@ayarane I wish I knew earlier before I chose burgers :( \n",
            "\n",
            "Iâm in hospital because I ate the chuckle sandwich burgers :( /j \n",
            "\n",
            "wdym lee know intentionally bought two burgers and saved one for hyunjin because gordon ramsayâs restaurants doesnââ¦ https://t.co/wDKqo196ap \n",
            "\n",
            "@juzaluna okay but their burgers are good :(( \n",
            "\n",
            "@BAYC2745 Is it allowed to flip burgers tho? :( \n",
            "\n",
            "\"Unfair.\" :(\n",
            "\n",
            "Sad vampire noises, she wished she could eat burgers in the morning https://t.co/yPS0ceKfPl \n",
            "\n",
            "I havenât watched Bobâs Burgers in many days :( \n",
            "\n",
            "----------------------------------------------------------------------------------------------------\n",
            "like\n",
            "@bluberrycream Oh no poor boy :( Holds Springter gently like hammed burger :( \n",
            "\n",
            "I feel like a burger :( \n",
            "\n",
            "I like earthbound but all I do is lose hp. I know itâs america but why is the healthcare so expensive :( guess Iâll just eated a burger \n",
            "\n",
            "@MYRIDOFFICIAL @jedwill1999 those are the thickest hot dog buns i've ever seen in my life :( they're like long burger buns im scared \n",
            "\n",
            "@strwbrryrabbit Itâs not like the burger making things Iâm just making fruit salads n shit :( \n",
            "\n",
            "Why is there burger slander on my tl :( I like everything on my burger!!! \n",
            "\n",
            "@lesmis456 Depends. Do you want to bite into potatowedges and feel like ur eating a whole potato? Loblaws. You wantâ¦ https://t.co/ZBxBTxIGs1 \n",
            "\n",
            "@lwashburn2 i used to get the one at mcnellies until i had one that tasted like they used plantains that were too râ¦ https://t.co/N3NwIpaXUV \n",
            "\n",
            "@Chilly_Pat I actually donât like any sort of fish :( Iâll try the nugget burger tho \n",
            "\n",
            "yikes im sorry anon &lt;/3 i dont like pickles too they destroy the whole entire burger/sandwich sometimes :( but youâ¦ https://t.co/356Bfw0iCO \n",
            "\n",
            "----------------------------------------------------------------------------------------------------\n",
            "king\n",
            "@bludsex burger king :( https://t.co/Rs1SFNwcxf \n",
            "\n",
            "My body is rejecting Burger King :( \n",
            "\n",
            "@HwanniePromotes Usto ko burger king :( \n",
            "\n",
            "i want sum burger king but they closed :( \n",
            "\n",
            "Im going to need someone to buy me some Burger King and yes idk why Iâm craving Burger King out of all things :( \n",
            "\n",
            "@gojosatoruism any time i've tried to have burger king since ive been a teenager, it just gives me the shits afterwards :( \n",
            "\n",
            "@BurgerKing do you still love me burger king :( https://t.co/beExz7mRt4 \n",
            "\n",
            "@camilosroxiie oh :(( burger king instead? ð \n",
            "\n",
            "not burger king giving me the wrong order &gt;:((( \n",
            "\n",
            "drive thru worker @ burger king fucked up my order &gt;:((( wanted sammich, got fries &gt;:((((((( \n",
            "\n",
            "----------------------------------------------------------------------------------------------------\n",
            "want\n",
            "hobi is eating a burger i want one too :( \n",
            "\n",
            "@kbbyhoon but I want to flip burgers :( \n",
            "\n",
            "@HwanniePromotes i want to eat burger and share it with fam :(( \n",
            "\n",
            "i want sum burger king but they closed :( \n",
            "\n",
            "@SquishyBlooper Jojo now i want a burger and its your fault buy me one now pls :( \n",
            "\n",
            "@Justaethan oh okay :( i have a burger ðð also do you want that? \n",
            "\n",
            "i want a burger :(( \n",
            "\n",
            "@lesmis456 Depends. Do you want to bite into potatowedges and feel like ur eating a whole potato? Loblaws. You wantâ¦ https://t.co/ZBxBTxIGs1 \n",
            "\n",
            "i want a burger its 9:37 am :( \n",
            "\n",
            "i want my burger ramly and keropok lekor :( \n",
            "\n",
            "----------------------------------------------------------------------------------------------------\n",
            "im\n",
            "@MYRIDOFFICIAL @jedwill1999 those are the thickest hot dog buns i've ever seen in my life :( they're like long burger buns im scared \n",
            "\n",
            "@howhighcanufly HEHE YAAAAY WENDYS WAT DID U GET FROM THERE? IM@GONNA GUESS A BURGER.. ALSO IM GOOD! im bORED JUSTâ¦ https://t.co/rBRdLjEnfT \n",
            "\n",
            "yikes im sorry anon &lt;/3 i dont like pickles too they destroy the whole entire burger/sandwich sometimes :( but youâ¦ https://t.co/356Bfw0iCO \n",
            "\n",
            "@Grande_hii Im honestly not that big of a picky eater, but the burger was cold, the chicken wasnt well cooked AT ALâ¦ https://t.co/7VbFbHBXpJ \n",
            "\n",
            "----------------------------------------------------------------------------------------------------\n",
            "dont\n",
            "yikes im sorry anon &lt;/3 i dont like pickles too they destroy the whole entire burger/sandwich sometimes :( but youâ¦ https://t.co/356Bfw0iCO \n",
            "\n",
            "----------------------------------------------------------------------------------------------------\n",
            "had\n",
            "i had a burger yest :( https://t.co/JROObe7Bke \n",
            "\n",
            "@imnickintl I've mainly had their pasta and It was bad :( and the burgers ok! \n",
            "\n",
            "@Harry1T6 I LOVE Burger Priest, I would have got it instead but I just had it yesterday lmao. My go to is the Doublâ¦ https://t.co/V3s8EPmUZa \n",
            "\n",
            "@WaYBaORaps u said that was the best burger u ever had &gt;:( \n",
            "\n",
            "@TheFrontBottoms God I wish I had the money :( Iâve had to make my own merch all the time lol but this looks so cool!!!!! \n",
            "\n",
            "@lwashburn2 i used to get the one at mcnellies until i had one that tasted like they used plantains that were too râ¦ https://t.co/N3NwIpaXUV \n",
            "\n",
            "then when i woke up i had to throw the burger and fries in the trash :(((( \n",
            "\n",
            "@nrnvan You're having burger? Should've invited me tho :( i had salad just now which is bland \n",
            "\n",
            "@redrobinburgers I had a bad experience. Actually a no experience. On my birthday nonetheless. Need transparency onâ¦ https://t.co/PygMan4OZL \n",
            "\n",
            "@burger_sha @DynamoSuperX I had my vice principal make me dump my ketone strips out and explain to everyone what they were for :( \n",
            "\n",
            "----------------------------------------------------------------------------------------------------\n",
            "not\n",
            "@LazyDudeDanny Not the burger! :( \n",
            "\n",
            "Carl's Jr and Hardee's are NOT the same @dan_bernstein @LaurenceWHolmes.  Moved to CO in 2018 and pulled into the dâ¦ https://t.co/Y5GUy7vQ5h \n",
            "\n",
            "@strwbrryrabbit Itâs not like the burger making things Iâm just making fruit salads n shit :( \n",
            "\n",
            "@TMobile hi Iâm not able to redeem my shake shack burger on your app :( \n",
            "\n",
            "@krikettt88 @DylanGelula I'm not vegan but hard agree on the sadness over the black bean burger loss at restaurantsâ¦ https://t.co/wnMpoXy9ns \n",
            "\n",
            "Got me a veggie burger :3 mjam, but not as tasty as daddy :( \n",
            "\n",
            "if i ever go to america i want to get mrbeast burger\n",
            "\n",
            "im not going if i wont get a dream burger &gt;:( \n",
            "\n",
            "i keep randomly crying throughout the day ever since burger passed..\n",
            "i think since i'm not constantly taking care oâ¦ https://t.co/wr4HfR6XhV \n",
            "\n",
            "Wow not only are these ânewâ fries not hot and crispy, but I ordered 2 big bacon classic combos and got cold burgerâ¦ https://t.co/8GfO5Bwg48 \n",
            "\n",
            "@Grande_hii Im honestly not that big of a picky eater, but the burger was cold, the chicken wasnt well cooked AT ALâ¦ https://t.co/7VbFbHBXpJ \n",
            "\n",
            "----------------------------------------------------------------------------------------------------\n",
            "have\n",
            "@swiff1337 @LogitechG i have no money :( \n",
            "\n",
            "@Harry1T6 I LOVE Burger Priest, I would have got it instead but I just had it yesterday lmao. My go to is the Doublâ¦ https://t.co/V3s8EPmUZa \n",
            "\n",
            "@artman Brindle room didn't survive the pandemic so I have no good burger places to take you this time :( \n",
            "\n",
            "@gojosatoruism any time i've tried to have burger king since ive been a teenager, it just gives me the shits afterwards :( \n",
            "\n",
            "@hughappyduo we donât have mcdonalds in our town :( but iâd say burgers \n",
            "\n",
            "@Cranky_00 Stipend isn't a salary :( 4000 kay to main burger kha jati thi ð.\n",
            "First salary should have been 15k butâ¦ https://t.co/MrRr0j4wQP \n",
            "\n",
            "@Justaethan oh okay :( i have a burger ðð also do you want that? \n",
            "\n",
            "When mr beast burger doesnât have a restaurant in Spain :( \n",
            "\n",
            "@toprak_mim @oatly @MictheVegan @RyanLum In our dreams: @PatrikBaboumian \n",
            "When we wake up: \"We don't have Moving Moâ¦ https://t.co/1QXJbBHgho \n",
            "\n",
            "@ataaashi itâs so bad , they donât have wraps / burgers / paella :( \n",
            "\n",
            "----------------------------------------------------------------------------------------------------\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**2. Researching Positive attitude tweets. Pushing to a MongoDB dbs. Looking for most frequent words. Looking for tweets with a geotag to see if we can determine where did positive attitudes come from. Listing 10 sentences where each of the most frequent words occurs to get the idea of what people are unhappy about.**"
      ],
      "metadata": {
        "id": "cQG8PjRVYlTY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Positive attitudes\n",
        "query2 = 'burger OR burgers :) -filter:retweets'\n",
        "\n",
        "data2 = twitter_api.search.tweets(q=query2, lang='en', count=100)\n",
        "\n",
        "min_id = data2['statuses'][-1]['id']\n",
        "for i in range(10):\n",
        "    tweets = twitter_api.search.tweets(q=query2, lang='en', max_id=min_id, count=100)\n",
        "    min_id = tweets['statuses'][-1]['id']\n",
        "    data2['statuses'] += tweets['statuses']\n",
        "\n",
        "statuses2 = data2['statuses']\n",
        "print(len(statuses2))\n",
        "coll_pos = db['cs2_coll_pos']\n",
        "# coll_pos.drop()\n",
        "# _ = coll_pos.insert_many(statuses2)"
      ],
      "metadata": {
        "id": "BQ0P-YVAO6lC",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9472cc63-37c6-466a-8d36-8a1598d21601"
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "404\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tweet_texts_pos = [ re.sub(r\"[^\\w\\s'#@]\", \"\", tweets['text']) for tweets in statuses2 ]\n",
        "print(tweet_texts_pos[0])\n",
        "words_pos = [ w for t in tweet_texts_pos for w in t.lower().split() ]\n",
        "words_pos = list(filter(lambda x: x not in exclude, words_pos))\n",
        "print(words_pos[1])"
      ],
      "metadata": {
        "id": "sj9YLEBLWE43",
        "outputId": "92da4f6e-da41-4435-a643-90ce2357a388",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "What are your favourite foods  Meatballs burger chicken katsu sweet and sour chicken I have too many haha but httpstcoK3xRAK5z5D\n",
            "foods\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "c = Counter(words_pos)\n",
        "top_words_pos = c.most_common()[:10]\n",
        "print(top_words_pos) # top 10\n",
        "\n",
        "pt = PrettyTable(field_names=['Word', 'Count'])\n",
        "[ pt.add_row(kv) for kv in c.most_common()[:10] ]\n",
        "pt.align['Word'], pt.align['Count'] = 'l', 'r'\n",
        "print(pt)"
      ],
      "metadata": {
        "id": "KAhY3xHFWLee",
        "outputId": "ab77f78a-800e-46ca-a341-1f7453434421",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[('burger', 244), ('burgers', 96), ('good', 33), ('get', 32), ('have', 30), ('like', 29), ('king', 28), ('just', 28), ('mob', 24), ('think', 22)]\n",
            "+---------+-------+\n",
            "| Word    | Count |\n",
            "+---------+-------+\n",
            "| burger  |   244 |\n",
            "| burgers |    96 |\n",
            "| good    |    33 |\n",
            "| get     |    32 |\n",
            "| have    |    30 |\n",
            "| like    |    29 |\n",
            "| king    |    28 |\n",
            "| just    |    28 |\n",
            "| mob     |    24 |\n",
            "| think   |    22 |\n",
            "+---------+-------+\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# similar attempt to find positive \"burger\" tweets with a geotag\n",
        "query_pos1 = { \"geo\": { \"$ne\": None } }\n",
        "cursor = coll_pos.find(query_pos1)\n",
        "\n",
        "for tweet in cursor:\n",
        "    print(tweet['text'])"
      ],
      "metadata": {
        "id": "sl8ELQL8Shtv"
      },
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for combo in top_words_pos:\n",
        "    print(combo[0])\n",
        "    query = { \"text\": { '$regex': '^.*'+ combo[0] + '.*$', '$options': 'si' } }\n",
        "    cursor = coll_pos.find(query)\n",
        "    i = 0\n",
        "    # Printing first 10 tweets\n",
        "    for tweet in cursor:\n",
        "        if tweet['text'] in printed:\n",
        "            continue\n",
        "        if i >= 10:\n",
        "            break\n",
        "        print(tweet['text'], '\\n')\n",
        "        printed.append(tweet['text'])\n",
        "        i += 1\n",
        "\n",
        "    print(\"-\"*100)"
      ],
      "metadata": {
        "id": "kP1YxDCicvgK",
        "outputId": "549002db-7e39-49dd-bdcc-56bc8a0707d3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "burger\n",
            "@ishyungshi fries and burger po from mcdo ate :) \n",
            "\n",
            "@billbison77 Sounds nice :) Iâll take w burger and if you need help with website i can help you build one with a takeout option ðâï¸ \n",
            "\n",
            "@cooolona hi po :)) i want a burger \n",
            "\n",
            "@kayla_eilhart Uhh. @McDonalds - Make a special burger without onion, so this lady can order anonymously next timeâ¦ https://t.co/Xka28HxJdC \n",
            "\n",
            "shout out to whoever put the veggie burger advert right after the \"eat meat and dairy :-)\" advert on ITV1 \n",
            "\n",
            "@TRIANGLE_MUPPET burger :) \n",
            "\n",
            "woul you rather eat pizza or ham burger :) https://t.co/tnGo3fReRH \n",
            "\n",
            "@Burger_Baron But don't tell him Greyhound is out of business right? :D \n",
            "\n",
            "@xdocvibez yes! burgers &amp; chicken tenders :) \n",
            "\n",
            "burger time :) \n",
            "\n",
            "----------------------------------------------------------------------------------------------------\n",
            "burgers\n",
            "@KuraiKiti This inspires hope for all burgers :) \n",
            "\n",
            "Follow for follow Burgers! Help you fellow burgers reach one hundred followers :D \n",
            "\n",
            "#TeamSehamOnKumu #KumuPh https://t.co/OG3uS6bWUa \n",
            "\n",
            "@1kebret over-sauced burgers deserve their own thread! :) \n",
            "\n",
            "@itsmeishmi Bread, cheese , meat and sweets :) not to fond of veggies . She has yet to try burgers but if she doesâ¦ https://t.co/Q0BQCMqnxo \n",
            "\n",
            "@Bowl_of_Worcel What episode? Bobs burgers is my comfort show and when I accidentally ate 8x the amount of gummiesâ¦ https://t.co/YJttuqDGJr \n",
            "\n",
            "@mrrobotoNFT done burgers :) \n",
            "\n",
            "@Overthehillprop Our local chippy. They prepare everything from scratch - mince the burgers from a cut of beef, makâ¦ https://t.co/vwSHFASKZU \n",
            "\n",
            "I'm afraid people will judge me so I order my sandwiches and burgers with lettuce only to take it off before I eat it. :) \n",
            "\n",
            "@Hardcorehayleee @/burgers.and.burpees :) \n",
            "\n",
            "@Caithlin_mully theyâre by far the best vegetarian burgers iâve found, iâd recommend them to anyone :) \n",
            "\n",
            "----------------------------------------------------------------------------------------------------\n",
            "good\n",
            "btw, hoshi's burger pic looks so good and i'm currently fasting :)))))) \n",
            "\n",
            "@calpicostrawb currently comforting is murderville a new will arnett show :) bob's burgers is always a good choice \n",
            "\n",
            "@BT_BlackThunder Hey everyone, come check out my Dying Light 2 Letâs Play on PS5! Iâm currently taking a good burgeâ¦ https://t.co/v1dt0NEhHe \n",
            "\n",
            "The way a good burger cheers you up :) \n",
            "\n",
            "went out by myself today. 2 malls, no way home, burger king, 2 sticks :))) feeling good good :))) haven't done this in awhile :))) \n",
            "\n",
            "Today was a good day\n",
            "- Got to use a power tool (immediate 7/10)\n",
            "- Ate at my fav fast food burger place for lunch (Iâ¦ https://t.co/GgGABqhbzG \n",
            "\n",
            "@mitchblevins To answer her question, sort of, give her a Tucker's onion burger. Looks and tastes like meat because it is meat. So good. :P \n",
            "\n",
            "@MarkCalc In fairness, you were eating. A burger :-)\n",
            "\n",
            "Your very good Open podcast somewhat blunted my memory. I senâ¦ https://t.co/Elyt1smQbT \n",
            "\n",
            "@fromthebunkerjr @ChewsViews @frangeladuo But are they as good as the Impossible burger from Burger King though? Weâ¦ https://t.co/3UXe8te3K6 \n",
            "\n",
            "@FanIroha Neat! :D\n",
            "I don't like burgers [unpatriotic I know! :(], but pickles and ketchup (and even cheese) are good! :) \n",
            "\n",
            "----------------------------------------------------------------------------------------------------\n",
            "get\n",
            "And the âeMplOyeRs sHoUld pAy yOu mOrEâ argument is fucking stupid. If my employer paid me what I should be gettingâ¦ https://t.co/VPxFkiPAy6 \n",
            "\n",
            "Eating a butter burger to get out of my feelings :) \n",
            "\n",
            "walked 3 blocks to get pan dulce and they had none :))))))))) had to come back in the rain also ð¯ð¯ð¯ð¯ \n",
            "\n",
            "@breakcorefan420 @gum_mp3 Hahaha I remember calling in sick the day after getting Arbyâs MEAT MOUNTAIN :p Iâm scareâ¦ https://t.co/5wfWtsuD4M \n",
            "\n",
            "@Saskgal80 @MarkEllison06 Lol! Well she said she wanted s burger mail and meant burger meal so I didnât get the fries and she was mad :) \n",
            "\n",
            "@CheekyVic Just get a non cheese burger ð u are an intelligent girl don't panic!!!!:) \n",
            "\n",
            "@Kitsune__Spirit i wish for vegetarian burger :) \n",
            "\n",
            "okay  guys  guys  im  going  to  burger  king  w  my  friends  after  my  exam  what  do  i  get  ??  i  get  to  lâ¦ https://t.co/iS3586e9Gx \n",
            "\n",
            "@_dawnw81 @GordonRamsay Hehe right on :) just curious...what'd ya get? Burger, I presume? \n",
            "\n",
            "Drinking hot chocolate, waiting for my train. Gonna get veggie burgers with Mandy and Dylan :) \n",
            "\n",
            "----------------------------------------------------------------------------------------------------\n",
            "have\n",
            "YOUTUBE!! HUH HUH i fell scroll serious :) recome a burger May i can you like literally everything in - finished do have \n",
            "\n",
            "ð do you have favorite brand that you like to eat?\n",
            "\n",
            "ð±: In &amp; Out Burger Jalapeno's a lot :))\n",
            "\n",
            "#ë ì´ë¸ #oneus https://t.co/6zKzV4c87t \n",
            "\n",
            "I only ever go to burger king for impossible burgers I'm so happy to finally have options even if it's minor :) \n",
            "\n",
            "@absomarvilla You also donât have a clue on how to spell my name! That said, when it comes to the #impossibleburgerâ¦ https://t.co/Lcy5F3o6lv \n",
            "\n",
            "@radiodreading And now I want a burger, dammit. :) No, I have no clue and I will finish the manga before I dare putâ¦ https://t.co/PQuUvMJnp2 \n",
            "\n",
            "@freshhmeatz @paradigmnft_ Negative. We only  have Burger King and McDonalds. :D \n",
            "\n",
            "@So_Ethereal Is like they use toast ð¤\n",
            "I have tested burger on toast b4 it is cool :) \n",
            "\n",
            "i have sudden plans to meet my friends today! first time after almost 2 years! I'm so glad I've only had a glass ofâ¦ https://t.co/gxYA8YTYEK \n",
            "\n",
            "I can't wait to eat these. Since I can't have pickles anymore, these will go on my burgers. :) https://t.co/VXtXUBKeW1 \n",
            "\n",
            "@banditocarly HIII this is my oc guy I made him very recently so I donât rlly have that many drawings for him and Iâ¦ https://t.co/84hKiq3WGu \n",
            "\n",
            "----------------------------------------------------------------------------------------------------\n",
            "like\n",
            "also iâd like to say that hungry jacks is australian burger king :) \n",
            "\n",
            "@tlrpclock when something like, annoying happens, you can always say \"not this\"! its basically the same as \"this suâ¦ https://t.co/PsK5xAp9wD \n",
            "\n",
            "I've been craving for sandwich/burger na homemade for like weeks na :))))) \n",
            "\n",
            "I saw a toy set that featured the Iron Man 3 IM suit and Happy Hogan and i was just like:\n",
            "\n",
            "\"Nah screw Iron man, i want Ham Burger Man :)\" \n",
            "\n",
            "@piyushchaudhry Then it would look like child of Pizza and Burger :) \n",
            "\n",
            "@burger_crypto @BitCannaGlobal calculated if you put 3000$ in bcna osmo you will receive like 1$ per day.  Bcna isâ¦ https://t.co/rUpl08UbYH \n",
            "\n",
            "@DrewNoles Like a signature burger :) x \n",
            "\n",
            "@YeetZmeN @Ghost_Burger @Wario64 it's a farming game like stardew valley :) \n",
            "\n",
            "Varsity Dream! \n",
            "He's eating a Dream burger &gt;:D \n",
            ".\n",
            "-retweets,likes,comments are cool-\n",
            "#dreamfanart #mcyt #smiletwt https://t.co/lNoClg5A9t \n",
            "\n",
            "@wnhyklvr ooh, yummy i like burgers hope u enjoy them then :D \n",
            "\n",
            "----------------------------------------------------------------------------------------------------\n",
            "king\n",
            "@georgeonthecob OH SORRY In my family we call dinner tea for some reason but weâre cooking burgers :D \n",
            "\n",
            "@almeidamarcell Burger King :) \n",
            "\n",
            "McDonalds o Burger King? :D \n",
            "\n",
            "on a second floor of a mang inasal alone eating burger king :)) https://t.co/c1bgDMLrr4 \n",
            "\n",
            "@IrlClefairy I GOT BURGER KING AND YES THIS WAS JANE INSPIRED!!! :D \n",
            "\n",
            "I didnât hit the curb at Burger King today :)) the iced coffees are the best everð­ \n",
            "\n",
            "@Sammyland6 I also love the old Burger King logo :) \n",
            "\n",
            "@MinishiFox Yeah Burger King has those :D \n",
            "\n",
            "@LacrimosaDeMag Burger king XDDD Sorry.... I just can't stop eating those damn cheese balls. I don't even care abouâ¦ https://t.co/svZVHuNcbk \n",
            "\n",
            "@ChefGruel Thatâs awesome! Well done! And keep making those burgers! I am going to travel all the way to you one of these days for one. :) \n",
            "\n",
            "----------------------------------------------------------------------------------------------------\n",
            "just\n",
            "@vegankitdotcom @zoltaire_ That's cool :) I just had a cheese burger. Non vegan, of course. \n",
            "\n",
            "@DoubleWideCap That's a $20 burger... just saying :) \n",
            "\n",
            "@themachine_07 Sameee. Was just kidding about that burger thing :p \n",
            "\n",
            "Going to do a Just Chatting cooking stream tonight! We're making BURGERS! ð Hoping to start around 8! (Have to go bâ¦ https://t.co/oi6msv8Sb2 \n",
            "\n",
            "@sanjisoup omg I'm so sorry to burger I did him an injustice, hes also a very cute worm :) \n",
            "\n",
            "----------------------------------------------------------------------------------------------------\n",
            "mob\n",
            "----------------------------------------------------------------------------------------------------\n",
            "think\n",
            "@Etown22 Thinking about that fish/burger combo :-) https://t.co/btRY3iyRhH \n",
            "\n",
            "I think tonight I'll Lab burger dad :) \n",
            "\n",
            "----------------------------------------------------------------------------------------------------\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**3. Finding 20 most popular retweeted tweets and 20 most liked tweets from positive attitude tweets. Looking for overlaps in who these people follow. Listing these accounts as primary contacts for targeted advertisement.**"
      ],
      "metadata": {
        "id": "_gx541IUY7bl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "tweets = [\n",
        "          (pop_tweet['retweet_count'], \n",
        "             pop_tweet['user']['screen_name'],\n",
        "             pop_tweet['text'])\n",
        "          for pop_tweet in statuses2\n",
        "            if 'retweeted_status' not in pop_tweet\n",
        "]\n",
        "pt = PrettyTable(field_names=['RT Count', 'Screen Name', 'Text'])\n",
        "[ pt.add_row(row) for row in sorted(tweets, reverse=True)[:20] ]\n",
        "pt.max_width['Text'] = 50\n",
        "pt.align= 'l'\n",
        "print(pt)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7O6E-MROZz7K",
        "outputId": "15077150-5593-49cb-ad6b-83bb7c4d43f1"
      },
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+----------+-----------------+----------------------------------------------------+\n",
            "| RT Count | Screen Name     | Text                                               |\n",
            "+----------+-----------------+----------------------------------------------------+\n",
            "| 30       | trioart412      | Cutie Girl Eat Burger ! :D                         |\n",
            "|          |                 |                                                    |\n",
            "|          |                 | Gift for @BellflowerBlu https://t.co/wwox3GPkmM    |\n",
            "| 23       | tanodniseham    | solid seham burgers, donât forget to continue      |\n",
            "|          |                 | saving your coins. we still donât know when will   |\n",
            "|          |                 | seham be nominated.â¦ https://t.co/UutMHLJ5Hv       |\n",
            "| 21       | SNLSABRINA      | i need more snl and sitcom moots. so if you like   |\n",
            "|          |                 | snl, b99, abbott elementary, new girl, modern      |\n",
            "|          |                 | family, superstore,â¦ https://t.co/ImIzYQuFmb       |\n",
            "| 15       | SehamDaghlasWW  | Good afternoon burgers. Pls use team ZacHam        |\n",
            "|          |                 | official tagline :)                                |\n",
            "|          |                 |                                                    |\n",
            "|          |                 | FRIDATE WITH ZACHAM                                |\n",
            "| 14       | TEAMSEHAMOFC    | Expect nothing prepare for the worst. If you       |\n",
            "|          |                 | didnât know, Team Seham has a Donation Drive set   |\n",
            "|          |                 | up. Rest assured thatâ¦ https://t.co/wZLNan0bHS     |\n",
            "| 8        | SehamDaghlasWW  | Good morning burgers :)                            |\n",
            "|          |                 |                                                    |\n",
            "|          |                 | #TeamSehamOnKumu                                   |\n",
            "|          |                 | #KumuPh https://t.co/JklMxgQXrL                    |\n",
            "| 8        | SehamDaghlasWW  | Drop your self love affirmations burgers. As many  |\n",
            "|          |                 | as you want :)                                     |\n",
            "|          |                 | #TeamSehamOnKumu                                   |\n",
            "|          |                 | #kumuPh https://t.co/2SfyGUt41A                    |\n",
            "| 7        | mochijapa       | ðAn useful expression related to the above        |\n",
            "|          |                 |                                                    |\n",
            "|          |                 | âXæ´¾=X ha= X person                               |\n",
            "|          |                 |                                                    |\n",
            "|          |                 | Use Xæ´¾ when you want to say âI prefer X than      |\n",
            "|          |                 | competâ¦ https://t.co/SmgzfY0YnA                    |\n",
            "| 6        | trioart412      | Yummy Burger king :) https://t.co/WTV6EBMx0F       |\n",
            "| 6        | gnfdreaming     | hi @MrBeast.                                       |\n",
            "|          |                 |                                                    |\n",
            "|          |                 | hi my friend  @dreamwastaken loves Beast Burgers,  |\n",
            "|          |                 | games, youtube and money ! he's streaming rn onâ¦   |\n",
            "|          |                 | https://t.co/GICpR9HEb1                            |\n",
            "| 6        | SehamDaghlasWW  | Last engagement booster for today's tp. Patulan    |\n",
            "|          |                 | nyo na to burgers :)                               |\n",
            "|          |                 |                                                    |\n",
            "|          |                 | LigTask SiSeham                                    |\n",
            "|          |                 | #PBBAdult3rdNomi https://t.co/6fQgndB464           |\n",
            "| 5        | iamMrZia        | Let's confuse Burgers :p https://t.co/SunLzvtEgk   |\n",
            "| 5        | TEAMSEHAMOFC    | Lets start building our Voting Team Burgers! DM if |\n",
            "|          |                 | youâre willing to join a committed voting team for |\n",
            "|          |                 | Seham :D                                           |\n",
            "|          |                 |                                                    |\n",
            "|          |                 | SAâ¦ https://t.co/aF0BQJI5Ey                        |\n",
            "| 4        | bbyxminie       | skeppy jr going to gloop gloop burgers :D          |\n",
            "|          |                 |                                                    |\n",
            "|          |                 | this isnât my c! charlie design i forgot what i    |\n",
            "|          |                 | made mine D: https://t.co/yVW0XJ7OuJ               |\n",
            "| 3        | zachupido       | kaya natin 'to Cookies, Charmers, and Burgers.     |\n",
            "|          |                 | Tweet lang ng tweet! :)                            |\n",
            "|          |                 |                                                    |\n",
            "|          |                 | FRIDATE WITH ZACHAM                                |\n",
            "|          |                 | #PBBInTheNameOfLove https://t.co/xNV6qES15l        |\n",
            "| 3        | zachupido       | kaya natin 'to Cookies, Charmers, and Burgers.     |\n",
            "|          |                 | Tweet lang ng tweet! :)                            |\n",
            "|          |                 |                                                    |\n",
            "|          |                 | FRIDATE WITH ZACHAM                                |\n",
            "|          |                 | #PBBInTheNameOfLove https://t.co/xNV6qES15l        |\n",
            "| 3        | TEAMSEHAMOFC    | Follow for follow Burgers! Help you fellow burgers |\n",
            "|          |                 | reach one hundred followers :D                     |\n",
            "|          |                 |                                                    |\n",
            "|          |                 | #TeamSehamOnKumu #KumuPh https://t.co/OG3uS6bWUa   |\n",
            "| 3        | HelenJRaine     | @mikesharman It was for @OneMinuteBriefs. Here are |\n",
            "|          |                 | the other winning submissions :) the Burger King   |\n",
            "|          |                 | one is also fliâ¦ https://t.co/An6YE9lGOp           |\n",
            "| 2        | YellingMadman   | This lil dude dreams about burgers just as much as |\n",
            "|          |                 | me, we're gonna get along just fine :)             |\n",
            "|          |                 | https://t.co/oK9FfnK77z                            |\n",
            "| 1        | tomhunternelson | Q: Your burgers started tasting a little different |\n",
            "|          |                 | to me in 2018. Am I going nuts?                    |\n",
            "|          |                 | A: Relax, youâre not nuts! :) Inâ¦                  |\n",
            "|          |                 | https://t.co/QDIKqnR1kI                            |\n",
            "+----------+-----------------+----------------------------------------------------+\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tweets = [\n",
        "          (pop_tweet['favorite_count'], \n",
        "             pop_tweet['user']['screen_name'],\n",
        "             pop_tweet['text'])\n",
        "          for pop_tweet in statuses2\n",
        "            if 'retweeted_status' not in pop_tweet\n",
        "]\n",
        "pt = PrettyTable(field_names=['Likes Count', 'Screen Name', 'Text'])\n",
        "[ pt.add_row(row) for row in sorted(tweets, reverse=True)[:20] ]\n",
        "pt.max_width['Text'] = 50\n",
        "pt.align= 'l'\n",
        "print(pt)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5tdLg2M5dB8G",
        "outputId": "7fcaef15-457c-4930-f420-15cc79a37e6c"
      },
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-------------+-----------------+----------------------------------------------------+\n",
            "| Likes Count | Screen Name     | Text                                               |\n",
            "+-------------+-----------------+----------------------------------------------------+\n",
            "| 188         | trioart412      | Cutie Girl Eat Burger ! :D                         |\n",
            "|             |                 |                                                    |\n",
            "|             |                 | Gift for @BellflowerBlu https://t.co/wwox3GPkmM    |\n",
            "| 140         | SNLSABRINA      | i need more snl and sitcom moots. so if you like   |\n",
            "|             |                 | snl, b99, abbott elementary, new girl, modern      |\n",
            "|             |                 | family, superstore,â¦ https://t.co/ImIzYQuFmb       |\n",
            "| 128         | Osiefish        | I gonna move my Geoguessr stream to 4 oâclock :) I |\n",
            "|             |                 | need burger                                        |\n",
            "| 99          | paricyte        | @meowriza thank you for your support on us burgers |\n",
            "|             |                 | meowriza :D                                        |\n",
            "| 74          | trioart412      | Yummy Burger king :) https://t.co/WTV6EBMx0F       |\n",
            "| 69          | bbyxminie       | skeppy jr going to gloop gloop burgers :D          |\n",
            "|             |                 |                                                    |\n",
            "|             |                 | this isnât my c! charlie design i forgot what i    |\n",
            "|             |                 | made mine D: https://t.co/yVW0XJ7OuJ               |\n",
            "| 44          | gnfdreaming     | hi @MrBeast.                                       |\n",
            "|             |                 |                                                    |\n",
            "|             |                 | hi my friend  @dreamwastaken loves Beast Burgers,  |\n",
            "|             |                 | games, youtube and money ! he's streaming rn onâ¦   |\n",
            "|             |                 | https://t.co/GICpR9HEb1                            |\n",
            "| 40          | tanodniseham    | solid seham burgers, donât forget to continue      |\n",
            "|             |                 | saving your coins. we still donât know when will   |\n",
            "|             |                 | seham be nominated.â¦ https://t.co/UutMHLJ5Hv       |\n",
            "| 33          | BillyStevens999 | Iâm in LA and I just drove past an in and out      |\n",
            "|             |                 | burger and Iâve never seen one before so it made   |\n",
            "|             |                 | me really really happy :)))                        |\n",
            "| 27          | mochijapa       | ðAn useful expression related to the above        |\n",
            "|             |                 |                                                    |\n",
            "|             |                 | âXæ´¾=X ha= X person                               |\n",
            "|             |                 |                                                    |\n",
            "|             |                 | Use Xæ´¾ when you want to say âI prefer X than      |\n",
            "|             |                 | competâ¦ https://t.co/SmgzfY0YnA                    |\n",
            "| 22          | iamMrZia        | Let's confuse Burgers :p https://t.co/SunLzvtEgk   |\n",
            "| 15          | ChanelMurder    | making turkey burgers and fries :-)                |\n",
            "| 14          | R0ninTheWolf    | *puts you on a Burger King crown*                  |\n",
            "|             |                 | You are now da queen/king of burgers!! :D          |\n",
            "| 13          | miskaknapek     | @mjtech01 @guido_burger @Philips Crypto mining in  |\n",
            "|             |                 | your toothbrush :-)                                |\n",
            "| 12          | mercutiokin     | made burgers tonight. dressed with blueberry jam   |\n",
            "|             |                 | goat cheese arugula &gt;:)                         |\n",
            "| 12          | YellingMadman   | This lil dude dreams about burgers just as much as |\n",
            "|             |                 | me, we're gonna get along just fine :)             |\n",
            "|             |                 | https://t.co/oK9FfnK77z                            |\n",
            "| 11          | friesforBrice   | went out by myself today. 2 malls, no way home,    |\n",
            "|             |                 | burger king, 2 sticks :))) feeling good good :)))  |\n",
            "|             |                 | haven't done this in awhile :)))                   |\n",
            "| 11          | TEAMSEHAMOFC    | Expect nothing prepare for the worst. If you       |\n",
            "|             |                 | didnât know, Team Seham has a Donation Drive set   |\n",
            "|             |                 | up. Rest assured thatâ¦ https://t.co/wZLNan0bHS     |\n",
            "| 11          | SehamDaghlasWW  | Good morning burgers :)                            |\n",
            "|             |                 |                                                    |\n",
            "|             |                 | #TeamSehamOnKumu                                   |\n",
            "|             |                 | #KumuPh https://t.co/JklMxgQXrL                    |\n",
            "| 10          | lowpolyburgers  | mottourisart was cause my old gamer name was       |\n",
            "|             |                 | mottouri (doesn't mean anything, was just a random |\n",
            "|             |                 | word) and :) 's artâ¦ https://t.co/hy8L3hC21M       |\n",
            "+-------------+-----------------+----------------------------------------------------+\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Unfortunately, upon closer examination of most liked and retweeted accounts that are related to burgers, we decided that this may be a poor tactic for determining accounts for advertisement. Unfortunately, most liked and most retweeted tweets that contain the word burger, are often related to something other than a burger."
      ],
      "metadata": {
        "id": "lHFjuJ1EdeZi"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tD6h0TglY6Dv"
      },
      "source": [
        "*-----------------\n",
        "# Done\n",
        "\n",
        "All set! \n",
        "\n",
        "** What do you need to submit?**\n",
        "\n",
        "* **Notebook File**: Save this IPython notebook, and find the notebook file in your folder (for example, \"filename.ipynb\"). This is the file you need to submit. Please make sure all the plotted tables and figures are in the notebook. If you used \"ipython notebook --pylab=inline\" to open the notebook, all the figures and tables should have shown up in the notebook.\n",
        "\n",
        "\n",
        "* **PPT Slides**: please prepare PPT slides (for 15 minutes' talk) to present about the case study . We will ask *all* teams to present their case studies in class for this case study. \n",
        "\n",
        "* **Report**: please prepare a report (less than 10 pages) to report what you found in the data.\n",
        "    * What data you collected? \n",
        "    * Why this topic is interesting or important to you? (Motivations)\n",
        "    * How did you analyse the data?\n",
        "    * What did you find in the data? \n",
        " \n",
        "     (please include figures or tables in the report, but no source code)\n",
        "\n",
        "Please compress all the files in a zipped file.\n",
        "\n",
        "\n",
        "** How to submit: **\n",
        "\n",
        "        Please submit through canvas.wpi.edu\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-FvDoMzSY6Dv"
      },
      "source": [
        "# Grading Criteria:\n",
        "\n",
        "**Totoal Points: 100**\n",
        "\n",
        "\n",
        "---------------------------------------------------------------------------\n",
        "**Notebook results:**\n",
        "    Points: 80\n",
        "\n",
        "\n",
        "    -----------------------------------\n",
        "    Question 1:\n",
        "    Points: 20\n",
        "    -----------------------------------\n",
        "    \n",
        "    -----------------------------------\n",
        "    Question 2:\n",
        "    Points: 20\n",
        "    -----------------------------------\n",
        "        \n",
        "    -----------------------------------\n",
        "    Question 3:\n",
        "    Points: 20\n",
        "    -----------------------------------\n",
        "  \n",
        "    -----------------------------------\n",
        "    Question 4:  Business question\n",
        "    Points: 20\n",
        "    -----------------------------------\n",
        "\n",
        "\n",
        "---------------------------------------------------------------------------\n",
        "**Slides (for 5-10 minutes of presentation): Story-telling**\n",
        "    Points: 20\n",
        "\n",
        "\n",
        "1. Motivation about the data collection, why the topic is interesting to you.\n",
        "    Points: 5 \n",
        "\n",
        "2. Communicating Results (figure/table)\n",
        "    Points: 10 \n",
        "\n",
        "3. Story telling (How all the parts (data, analysis, result) fit together as a story?)\n",
        "    Points: 5 \n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "metadata": {
        "id": "2Wy1xam0Y6Dw"
      },
      "outputs": [],
      "source": [
        ""
      ]
    }
  ],
  "metadata": {
    "anaconda-cloud": {},
    "kernel_info": {
      "name": "python3"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.5"
    },
    "nteract": {
      "version": "0.2.0"
    },
    "colab": {
      "name": "CaseStudy2_MongoDB.ipynb",
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}