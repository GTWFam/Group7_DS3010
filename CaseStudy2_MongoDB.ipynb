{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/GTWFam/Group7_DS3010/blob/main/CaseStudy2_MongoDB.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IQZqJy0gY6Dl"
      },
      "source": [
        "# Case Study 2 : Putting Twitter Data into the Cloud\n",
        "\n",
        "Due Date: 2/15/2020, **BEFORE the beginning of class at 2:00pm EST**\n",
        "\n",
        "## **NOTE: There are *always* last minute issues submitting the case studies.  DO NOT WAIT UNTIL THE LAST MINUTE!**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JyNhpJN5Y6Dn"
      },
      "source": [
        "<a title=\"Fabi√°n Alexis [CC BY-SA (https://creativecommons.org/licenses/by-sa/3.0)]\" href=\"https://commons.wikimedia.org/wiki/File:Antu_mongodb.svg\"><img width=\"50\" alt=\"Antu mongodb\" src=\"https://upload.wikimedia.org/wikipedia/commons/thumb/f/f9/Antu_mongodb.svg/512px-Antu_mongodb.svg.png\"></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DhXEvLb5Y6Do"
      },
      "source": [
        "**TEAM Members:** Please EDIT this cell and add the names of all the team members in your team\n",
        "\n",
        "    Jacob Bissonette\n",
        "    Austin Franklin \n",
        "    Yuriy Kamenivskyy \n",
        "    Garrett McMerriman\n",
        "    Bill Hoang Pham"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IdtCbjp9Y6Do"
      },
      "source": [
        "**Don't forget!**\n",
        "* You will need to install the pymongo library to access MongoDB\n",
        " * pip install pymongo\n",
        "* You will also need to install dnspython to access the cloud version of MongoDB\n",
        " * pip install dnspython\n",
        "\n",
        "** NOTE **\n",
        "* **Please don't forget to save the notebook frequently when working in IPython Notebook, otherwise the changes you made can be lost**."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1R87hP_pY6Dq"
      },
      "source": [
        "# Problem 1 (20 points):  Get a cloud database account using MongoDB Atlas"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Q10TAFcOY6Dq"
      },
      "source": [
        "Get a free cloud hosted MongoDB database account at https://www.mongodb.com/atlas/database.  You will need to: \n",
        "\n",
        "* Create a database cluster using the MongoDB web interface\n",
        "* Get your MongoDB credentials\n",
        "* Create a document collection in MongoBD\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7dOckKukY6Ds"
      },
      "source": [
        "# Problem 2 (20 points):  Read Twitter data into your cloud MongoDB database"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-yQgleDnY6Ds"
      },
      "source": [
        "Gather Twitter data and upload it to your cloud database.  You will need to:\n",
        "\n",
        "* Get your cloubd MongoDB credentials using the MongoDB web interface\n",
        "* Insert those credentials into your Juypyter notebook using pymongo\n",
        "* Gather Twitter data as in Case Study 1\n",
        "* Upload your Twitter data to the MongoDB cloud document collection\n",
        "\n",
        "Note, to do you this question remember that you will need *two sets of credentials*\n",
        "\n",
        "* One set for the MongoDB Atlas database\n",
        "* One set for the Twitter developed API\n",
        "\n",
        "Of course, there are not the same!"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "! pip install pymongo\n",
        "! pip install dnspython\n"
      ],
      "metadata": {
        "id": "zHd0WyWXrT7g",
        "outputId": "253ffe66-1485-4251-c557-3c6b741d8d2f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: pymongo in /usr/local/lib/python3.7/dist-packages (4.0.1)\n",
            "Requirement already satisfied: dnspython in /usr/local/lib/python3.7/dist-packages (2.2.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "MO0paphxY6Dq",
        "outputId": "5c0a2aeb-acb6-4c7b-a621-8778da3a4cda",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "#----------------------------------------------\n",
        "# Your code starts here\n",
        "#   Please add comments or text cells in between to explain the general idea of each block of the code.\n",
        "#   Please feel free to add more cells below this cell if necessary\n",
        "import pymongo\n",
        "import json\n",
        "\n",
        "from google.colab import drive\n",
        "\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "data = {}\n",
        "    \n",
        "# Extracting the saved credentials from the drive\n",
        "with open('drive/MyDrive/ds3010_2022/credentials.txt', 'r') as f:\n",
        "    data = json.load(f)\n",
        "CONSUMER_KEY = data[\"consumer_key\"]\n",
        "CONSUMER_SECRET = data[\"consumer_secret\"]\n",
        "OAUTH_TOKEN = data[\"oauth_token\"]\n",
        "OAUTH_TOKEN_SECRET = data[\"oauth_token_secret\"]\n",
        "mongodb_url = data[\"mongodb_url\"]\n",
        "\n",
        "client = pymongo.MongoClient(mongodb_url)\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Getting the Database and Collection from MongoDB\n",
        "db = client['DS3010']\n",
        "coll = db['CS2']"
      ],
      "metadata": {
        "id": "w1p9Z5f3sctw"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "! pip install twitter"
      ],
      "metadata": {
        "id": "qD5dgzJlsTIC",
        "outputId": "c356231a-137c-4fa5-8fd2-1ff70d917c7a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: twitter in /usr/local/lib/python3.7/dist-packages (1.19.3)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "my4IUYVvY6Ds"
      },
      "outputs": [],
      "source": [
        "#----------------------------------------------\n",
        "# Your code starts here\n",
        "#   Please add comments or text cells in between to explain the general idea of each block of the code.\n",
        "#   Please feel free to add more cells below this cell if necessary\n",
        "import twitter\n",
        "\n",
        "# See https://dev.twitter.com/docs/auth/oauth for more information \n",
        "# on Twitter's OAuth implementation.\n",
        "\n",
        "auth = twitter.oauth.OAuth(OAUTH_TOKEN, OAUTH_TOKEN_SECRET,\n",
        "                           CONSUMER_KEY, CONSUMER_SECRET)\n",
        "\n",
        "twitter_api = twitter.Twitter(auth=auth)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "query = \"macbook pro 2021\"\n",
        "\n",
        "data = twitter_api.search.tweets(q=query, lang='en', count=100)\n",
        "\n",
        "min_id = data['statuses'][-1]['id']\n",
        "for i in range(7):\n",
        "    tweets = twitter_api.search.tweets(q=query, lang='en', max_id=min_id, count=100)\n",
        "    min_id = tweets['statuses'][-1]['id']\n",
        "    data['statuses'] += tweets['statuses']\n"
      ],
      "metadata": {
        "id": "8DgXTFziu12O"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "statuses = data['statuses']\n",
        "coll.drop()\n",
        "_ = coll.insert_many(statuses)"
      ],
      "metadata": {
        "id": "2ZdWGUR2vqZu"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ui6DxP0lY6Dt"
      },
      "source": [
        "# Problem 3 (20 points):  Use a regular expression to read a subset of your Tweets out of MongoDB"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "63qOpjc9Y6Dt"
      },
      "source": [
        "Use regular expressions to analyze properties of your data.  For example, you can \n",
        "\n",
        "* search for trends that have a large volume, \n",
        "* search for tweets with geotags, \n",
        "* search for tweets that can contain a certain string,\n",
        "* anything else you think might be useful for a product!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "id": "5W_39LCaY6Du",
        "outputId": "c893650c-5870-442e-f208-0d5e63f8abb5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Tech bro/sis, final year brethren, graphic designers, writers, anyone in need of a good laptop or money, this tweet‚Ä¶ https://t.co/REQeY1t0YZ\n",
            "Client‚Äôs MacBook Pro 14‚Äù 2021 model/16GB Ram/512GB SSD M1Pro chip - Ready 4 delivery/ More of this Still in stock‚Ä¶ https://t.co/AzX70Jcqfh\n",
            "Nah!!! Apple is Goated for their User Experience\n",
            "\n",
            "Might fuck around and drop an extra $5K+ to pick up an iMac and u‚Ä¶ https://t.co/22SciRqcZY\n",
            "This season, @xendfinance is giving out a brand new MacBook pro 2021, and a prize pool of $2,000, to 20 savers \n",
            "\n",
            "To‚Ä¶ https://t.co/8bqmdhSbYb\n",
            "New saving challenge:\n",
            "\n",
            "You save N3,000 every day from now till February 28th, and at the end, you win a MacBook Pro‚Ä¶ https://t.co/2YFPEiTmXY\n",
            "The battery life on the 2021 Macbook Pro is wild y'all... I've been using my computer for an hour &amp; it still says t‚Ä¶ https://t.co/vtoMoLyDj5\n",
            "In the spirit of love &amp; financial responsibility, @xendfinance is giving out a BRAND NEW MacBook Pro 2021, and priz‚Ä¶ https://t.co/YPXNlAV5sZ\n",
            "The 2021 MacBook pro is such a beautiful and powerful machine ü•∞\n",
            "\n",
            "AND @Xendfinance WANTS TO DASH YOU A BRAND NEW ONE‚Ä¶ https://t.co/k9XnLj3KYa\n",
            "Client‚Äôs MacBook Pro 13inch/512GB SSD/ 2021 model delivered / Thank u Signum Advocates 4 the orders\n",
            "\n",
            "Contact us for‚Ä¶ https://t.co/6c2BasfiSX\n"
          ]
        }
      ],
      "source": [
        "#----------------------------------------------\n",
        "# Your code starts here\n",
        "#   Please add comments or text cells in between to explain the general idea of each block of the code.\n",
        "#   Please feel free to add more cells below this cell if necessary\n",
        "\n",
        "query = { \"favorite_count\": { \"$gt\": 20 } }\n",
        "cursor = coll.find(query)\n",
        "\n",
        "for tweet in cursor:\n",
        "    print(tweet['text'])"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### There are no tweets that has a geotag"
      ],
      "metadata": {
        "id": "yr-d93Db4iUX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "query2 = { \"geo\": { \"$ne\": None } }\n",
        "cursor = coll.find(query2)\n",
        "\n",
        "for tweet in cursor:\n",
        "    print(tweet['text'])"
      ],
      "metadata": {
        "id": "CPd_H_VX7lDD"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "query3 = { \"text\": { '$regex': '^.*cool.*$', '$options': 'si' } }\n",
        "cursor = coll.find(query3)\n",
        "\n",
        "for tweet in cursor:\n",
        "    print(tweet['text'])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zkvtx5Z242yQ",
        "outputId": "db407c2c-1f7a-48b8-fabd-9da932f59b06"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "TECOOL Custodia per 2021 MacBook Pro 14, MacBook Air/Pro 13, 13,5 Surface Laptop, 14‚Äù Huawei Matebook, ASUS Zenbook‚Ä¶ https://t.co/H9wSWkPrpD\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "query4 = { \"text\": { '$regex': '^.*battery.*$', '$options': 'si' } }\n",
        "cursor = coll.find(query4)\n",
        "\n",
        "for tweet in cursor:\n",
        "    print(tweet['text'])"
      ],
      "metadata": {
        "id": "DGwFPOgWAOB7",
        "outputId": "ca77d0a0-2415-4fc5-d61a-6cd20ca57622",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The battery life on the 2021 Macbook Pro is wild y'all... I've been using my computer for an hour &amp; it still says t‚Ä¶ https://t.co/vtoMoLyDj5\n",
            "RT @wccftech: Apple‚Äôs 2021 MacBook Pro Lasts 60% Longer Than the Best High-End Notebook‚Äôs Battery Timing, Claims Ne‚Ä¶ https://t.co/FuZ58FkCog\n",
            "RT @wccftech: Apple‚Äôs 2021 MacBook Pro Lasts 60% Longer Than the Best High-End Notebook‚Äôs Battery Timing, Claims New Test https://t.co/NFvB‚Ä¶\n",
            "RT @wccftech: Apple‚Äôs 2021 MacBook Pro Lasts 60% Longer Than the Best High-End Notebook‚Äôs Battery Timing, Claims New Test https://t.co/NFvB‚Ä¶\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "collapsed": true,
        "id": "n0iZmkh7Y6Du"
      },
      "source": [
        "# Problem 4 (20 points): Business question \n",
        "\n",
        "Run some additional experiments with your data to gain familiarity with the MongoDB.\n",
        "\n",
        "* Come up with a business question that Twitter data and MongoDB could help answer.\n",
        "* Decribe the business case.\n",
        "* How could MongoDB help a company to scale up its computation environment?"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Our business lies in helping entrepreneurs better understand their market using twitter data, prior to them making an investing decision. Our research model is flexible and can be used to research just about any topic.\n",
        "\n",
        "The model is the following: \n",
        "1. We determine the market's underserved needs by analyzing negative sentiment tweets related to the business of choice. After collecting all negative sentiment tweets, we determine the most frequently occuring words, and then search for tweets containing these words to get an idea of what the problem / underserved need may be.\n",
        "2. We determine the market's table stakes‚Äì‚Äì needs that are satisfied by all the other competitors, and thus have to be satisfied by us as well‚Äì‚Äì to do this we follow an identical algorithm to problem 1, but now we query for tweets with a positive sentiment.\n",
        "3. We identify the creators of most liked and most retweeted positive tweets; and then look for overlapping accounts that they follow. These accounts will be our primary contacts for targeted advertisement of the new product.\n",
        "\n",
        "MongoDB helps us organize this data into different collection and use regular expressions to query data efficiently and accurately."
      ],
      "metadata": {
        "id": "X9QQ8ONpeJgh"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**1. Researching Negative attitude tweets. Pushing to a MongoDB dbs. Looking for most frequent words. Looking for tweets with a geotag to see if we can determine where did negative attitudes come from. Listing 10 sentences where each of the most frequent words occurs to get the idea of what people are unhappy about.**"
      ],
      "metadata": {
        "id": "pzjdfWPeYBkY"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "id": "Q_JRP_b5Y6Dv",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9dc8c347-5778-43b4-998f-b4b69dbe507b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "179\n"
          ]
        }
      ],
      "source": [
        "# Negative attitudes\n",
        "query1 = 'burger OR burgers :( -filter:retweets'\n",
        "\n",
        "data1 = twitter_api.search.tweets(q=query1, lang='en', count=100)\n",
        "\n",
        "min_id = data1['statuses'][-1]['id']\n",
        "for i in range(10):\n",
        "    tweets = twitter_api.search.tweets(q=query1, lang='en', max_id=min_id, count=100)\n",
        "    min_id = tweets['statuses'][-1]['id']\n",
        "    data1['statuses'] += tweets['statuses']\n",
        "\n",
        "statuses1 = data1['statuses']\n",
        "print(len(statuses1))\n",
        "coll_neg = db['cs2_coll_neg']\n",
        "# coll_neg.drop()\n",
        "# _ = coll_neg.insert_many(statuses1)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Similar to Case Study 1, looking at most common words\n",
        "\n",
        "import re\n",
        "exclude = ['rt', 'in', 'the', 'for','of', 'to', 'and', 'a', 'is', 'are', 'on', 'from', 'that', 'this', 'these', 'with', 'what', 'it', 'if', 'or', 'but', 'your', 'be', 'you', 'my', 'at', 'd', 'its', 'i', 'so', 'was', 'he', 'me', 'no', 'about']\n",
        "\n",
        "tweet_texts_neg = [ re.sub(r\"[^\\w\\s'#@]\", \"\", tweets['text']) for tweets in statuses1 ]\n",
        "print(tweet_texts_neg[0])\n",
        "words_neg = [ w for t in tweet_texts_neg for w in t.lower().split() ]\n",
        "words_neg = list(filter(lambda x: x not in exclude, words_neg))\n",
        "print(words_neg[1])"
      ],
      "metadata": {
        "id": "w6eMTHwBUqgT",
        "outputId": "3df8a1fc-f97f-4902-ec96-bc57e4163202",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "shadow dedede update Hammed burger \n",
            "dedede\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from prettytable import PrettyTable\n",
        "from collections import Counter\n",
        "\n",
        "c = Counter(words_neg)\n",
        "top_words_neg = c.most_common()[:10]\n",
        "print(top_words_neg) # top 10\n",
        "\n",
        "pt = PrettyTable(field_names=['Word', 'Count'])\n",
        "[ pt.add_row(kv) for kv in c.most_common()[:10] ]\n",
        "pt.align['Word'], pt.align['Count'] = 'l', 'r'\n",
        "print(pt)"
      ],
      "metadata": {
        "id": "G4TVsj3fVX5K",
        "outputId": "aef31fc3-5c00-451b-e6c8-7d3ee6f36294",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[('burger', 130), ('burgers', 28), ('like', 18), ('king', 18), ('want', 18), ('im', 17), ('dont', 15), ('had', 14), ('not', 12), ('have', 12)]\n",
            "+---------+-------+\n",
            "| Word    | Count |\n",
            "+---------+-------+\n",
            "| burger  |   130 |\n",
            "| burgers |    28 |\n",
            "| like    |    18 |\n",
            "| king    |    18 |\n",
            "| want    |    18 |\n",
            "| im      |    17 |\n",
            "| dont    |    15 |\n",
            "| had     |    14 |\n",
            "| not     |    12 |\n",
            "| have    |    12 |\n",
            "+---------+-------+\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Attempt to look for negative sentiment tweets with a geo-tag. Might give us an idea of where competitors fail or make bad burgers\n",
        "query_neg1 = { \"geo\": { '$ne': None } }\n",
        "cursor = coll_neg.find(query_neg1)\n",
        "\n",
        "for tweet in cursor:\n",
        "    print(tweet['text'])"
      ],
      "metadata": {
        "id": "djfhuFZISA1t"
      },
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Looking at tweets that have the most used words\n",
        "for combo in top_words_neg:\n",
        "    print(combo[0])\n",
        "    query = { \"text\": { '$regex': '^.* '+ combo[0] + ' .*$', '$options': 'si' } }\n",
        "    cursor = coll_neg.find(query)\n",
        "    i = 0\n",
        "    # Printing first 10 tweets\n",
        "    printed = []\n",
        "    for tweet in cursor:\n",
        "        # Filtering out the not useful and spamming data\n",
        "        if tweet['text'] in printed:\n",
        "            continue\n",
        "        if i >= 10:\n",
        "            break\n",
        "        print(tweet['text'], '\\n')\n",
        "        printed.append(tweet['text'])\n",
        "        i += 1\n",
        "\n",
        "    print(\"-\"*100)"
      ],
      "metadata": {
        "id": "YORgp_sIbIB0",
        "outputId": "ea96e8ea-80d3-4220-edfa-551f121bb243",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "burger\n",
            "P. Terry‚Äôs got rid of their hatch green chile burger :( \n",
            "\n",
            "I hate my bf rn, he ate my burger I‚Äôve been saving all night bc I was drunk :( \n",
            "\n",
            "shadow dedede update! Hammed burger :( \n",
            "\n",
            "i had a burger yest :( https://t.co/JROObe7Bke \n",
            "\n",
            "hobi is eating a burger i want one too :( \n",
            "\n",
            "Wanted to try the @JackBox Heinz Dip and Crunch Bacon Cheeseburger tonight - ended up with a dry burger and no dip‚Ä¶ https://t.co/D75PKV7ngh \n",
            "\n",
            "@Harry1T6 I LOVE Burger Priest, I would have got it instead but I just had it yesterday lmao. My go to is the Doubl‚Ä¶ https://t.co/V3s8EPmUZa \n",
            "\n",
            "Checking Etsy to see if anyone's made the burger shirt from the cover of Nona the Ninth yet. Can't find one. :( \n",
            "\n",
            "@bludsex burger king :( https://t.co/Rs1SFNwcxf \n",
            "\n",
            "til to melt vegan cheese on ur burger in the oven bc otherwise it will slide away :( \n",
            "\n",
            "----------------------------------------------------------------------------------------------------\n",
            "burgers\n",
            "@imnickintl I've mainly had their pasta and It was bad :( and the burgers ok! \n",
            "\n",
            "@kbbyhoon but I want to flip burgers :( \n",
            "\n",
            "Come on I need burgers I'm starving :( https://t.co/JKttxdNyr1 \n",
            "\n",
            "@ayarane I wish I knew earlier before I chose burgers :( \n",
            "\n",
            "I‚Äôm in hospital because I ate the chuckle sandwich burgers :( /j \n",
            "\n",
            "wdym lee know intentionally bought two burgers and saved one for hyunjin because gordon ramsay‚Äôs restaurants doesn‚Äô‚Ä¶ https://t.co/wDKqo196ap \n",
            "\n",
            "@juzaluna okay but their burgers are good :(( \n",
            "\n",
            "@BAYC2745 Is it allowed to flip burgers tho? :( \n",
            "\n",
            "\"Unfair.\" :(\n",
            "\n",
            "Sad vampire noises, she wished she could eat burgers in the morning https://t.co/yPS0ceKfPl \n",
            "\n",
            "I haven‚Äôt watched Bob‚Äôs Burgers in many days :( \n",
            "\n",
            "----------------------------------------------------------------------------------------------------\n",
            "like\n",
            "@bluberrycream Oh no poor boy :( Holds Springter gently like hammed burger :( \n",
            "\n",
            "I feel like a burger :( \n",
            "\n",
            "I like earthbound but all I do is lose hp. I know it‚Äôs america but why is the healthcare so expensive :( guess I‚Äôll just eated a burger \n",
            "\n",
            "@MYRIDOFFICIAL @jedwill1999 those are the thickest hot dog buns i've ever seen in my life :( they're like long burger buns im scared \n",
            "\n",
            "@strwbrryrabbit It‚Äôs not like the burger making things I‚Äôm just making fruit salads n shit :( \n",
            "\n",
            "Why is there burger slander on my tl :( I like everything on my burger!!! \n",
            "\n",
            "@lesmis456 Depends. Do you want to bite into potatowedges and feel like ur eating a whole potato? Loblaws. You want‚Ä¶ https://t.co/ZBxBTxIGs1 \n",
            "\n",
            "@lwashburn2 i used to get the one at mcnellies until i had one that tasted like they used plantains that were too r‚Ä¶ https://t.co/N3NwIpaXUV \n",
            "\n",
            "@Chilly_Pat I actually don‚Äôt like any sort of fish :( I‚Äôll try the nugget burger tho \n",
            "\n",
            "yikes im sorry anon &lt;/3 i dont like pickles too they destroy the whole entire burger/sandwich sometimes :( but you‚Ä¶ https://t.co/356Bfw0iCO \n",
            "\n",
            "----------------------------------------------------------------------------------------------------\n",
            "king\n",
            "@bludsex burger king :( https://t.co/Rs1SFNwcxf \n",
            "\n",
            "My body is rejecting Burger King :( \n",
            "\n",
            "@HwanniePromotes Usto ko burger king :( \n",
            "\n",
            "i want sum burger king but they closed :( \n",
            "\n",
            "Im going to need someone to buy me some Burger King and yes idk why I‚Äôm craving Burger King out of all things :( \n",
            "\n",
            "@gojosatoruism any time i've tried to have burger king since ive been a teenager, it just gives me the shits afterwards :( \n",
            "\n",
            "@BurgerKing do you still love me burger king :( https://t.co/beExz7mRt4 \n",
            "\n",
            "@camilosroxiie oh :(( burger king instead? üëÄ \n",
            "\n",
            "not burger king giving me the wrong order &gt;:((( \n",
            "\n",
            "drive thru worker @ burger king fucked up my order &gt;:((( wanted sammich, got fries &gt;:((((((( \n",
            "\n",
            "----------------------------------------------------------------------------------------------------\n",
            "want\n",
            "hobi is eating a burger i want one too :( \n",
            "\n",
            "@kbbyhoon but I want to flip burgers :( \n",
            "\n",
            "@HwanniePromotes i want to eat burger and share it with fam :(( \n",
            "\n",
            "i want sum burger king but they closed :( \n",
            "\n",
            "@SquishyBlooper Jojo now i want a burger and its your fault buy me one now pls :( \n",
            "\n",
            "@Justaethan oh okay :( i have a burger üçîüçî also do you want that? \n",
            "\n",
            "i want a burger :(( \n",
            "\n",
            "@lesmis456 Depends. Do you want to bite into potatowedges and feel like ur eating a whole potato? Loblaws. You want‚Ä¶ https://t.co/ZBxBTxIGs1 \n",
            "\n",
            "i want a burger its 9:37 am :( \n",
            "\n",
            "i want my burger ramly and keropok lekor :( \n",
            "\n",
            "----------------------------------------------------------------------------------------------------\n",
            "im\n",
            "@MYRIDOFFICIAL @jedwill1999 those are the thickest hot dog buns i've ever seen in my life :( they're like long burger buns im scared \n",
            "\n",
            "@howhighcanufly HEHE YAAAAY WENDYS WAT DID U GET FROM THERE? IM@GONNA GUESS A BURGER.. ALSO IM GOOD! im bORED JUST‚Ä¶ https://t.co/rBRdLjEnfT \n",
            "\n",
            "yikes im sorry anon &lt;/3 i dont like pickles too they destroy the whole entire burger/sandwich sometimes :( but you‚Ä¶ https://t.co/356Bfw0iCO \n",
            "\n",
            "@Grande_hii Im honestly not that big of a picky eater, but the burger was cold, the chicken wasnt well cooked AT AL‚Ä¶ https://t.co/7VbFbHBXpJ \n",
            "\n",
            "----------------------------------------------------------------------------------------------------\n",
            "dont\n",
            "yikes im sorry anon &lt;/3 i dont like pickles too they destroy the whole entire burger/sandwich sometimes :( but you‚Ä¶ https://t.co/356Bfw0iCO \n",
            "\n",
            "----------------------------------------------------------------------------------------------------\n",
            "had\n",
            "i had a burger yest :( https://t.co/JROObe7Bke \n",
            "\n",
            "@imnickintl I've mainly had their pasta and It was bad :( and the burgers ok! \n",
            "\n",
            "@Harry1T6 I LOVE Burger Priest, I would have got it instead but I just had it yesterday lmao. My go to is the Doubl‚Ä¶ https://t.co/V3s8EPmUZa \n",
            "\n",
            "@WaYBaORaps u said that was the best burger u ever had &gt;:( \n",
            "\n",
            "@TheFrontBottoms God I wish I had the money :( I‚Äôve had to make my own merch all the time lol but this looks so cool!!!!! \n",
            "\n",
            "@lwashburn2 i used to get the one at mcnellies until i had one that tasted like they used plantains that were too r‚Ä¶ https://t.co/N3NwIpaXUV \n",
            "\n",
            "then when i woke up i had to throw the burger and fries in the trash :(((( \n",
            "\n",
            "@nrnvan You're having burger? Should've invited me tho :( i had salad just now which is bland \n",
            "\n",
            "@redrobinburgers I had a bad experience. Actually a no experience. On my birthday nonetheless. Need transparency on‚Ä¶ https://t.co/PygMan4OZL \n",
            "\n",
            "@burger_sha @DynamoSuperX I had my vice principal make me dump my ketone strips out and explain to everyone what they were for :( \n",
            "\n",
            "----------------------------------------------------------------------------------------------------\n",
            "not\n",
            "@LazyDudeDanny Not the burger! :( \n",
            "\n",
            "Carl's Jr and Hardee's are NOT the same @dan_bernstein @LaurenceWHolmes.  Moved to CO in 2018 and pulled into the d‚Ä¶ https://t.co/Y5GUy7vQ5h \n",
            "\n",
            "@strwbrryrabbit It‚Äôs not like the burger making things I‚Äôm just making fruit salads n shit :( \n",
            "\n",
            "@TMobile hi I‚Äôm not able to redeem my shake shack burger on your app :( \n",
            "\n",
            "@krikettt88 @DylanGelula I'm not vegan but hard agree on the sadness over the black bean burger loss at restaurants‚Ä¶ https://t.co/wnMpoXy9ns \n",
            "\n",
            "Got me a veggie burger :3 mjam, but not as tasty as daddy :( \n",
            "\n",
            "if i ever go to america i want to get mrbeast burger\n",
            "\n",
            "im not going if i wont get a dream burger &gt;:( \n",
            "\n",
            "i keep randomly crying throughout the day ever since burger passed..\n",
            "i think since i'm not constantly taking care o‚Ä¶ https://t.co/wr4HfR6XhV \n",
            "\n",
            "Wow not only are these ‚Äúnew‚Äù fries not hot and crispy, but I ordered 2 big bacon classic combos and got cold burger‚Ä¶ https://t.co/8GfO5Bwg48 \n",
            "\n",
            "@Grande_hii Im honestly not that big of a picky eater, but the burger was cold, the chicken wasnt well cooked AT AL‚Ä¶ https://t.co/7VbFbHBXpJ \n",
            "\n",
            "----------------------------------------------------------------------------------------------------\n",
            "have\n",
            "@swiff1337 @LogitechG i have no money :( \n",
            "\n",
            "@Harry1T6 I LOVE Burger Priest, I would have got it instead but I just had it yesterday lmao. My go to is the Doubl‚Ä¶ https://t.co/V3s8EPmUZa \n",
            "\n",
            "@artman Brindle room didn't survive the pandemic so I have no good burger places to take you this time :( \n",
            "\n",
            "@gojosatoruism any time i've tried to have burger king since ive been a teenager, it just gives me the shits afterwards :( \n",
            "\n",
            "@hughappyduo we don‚Äôt have mcdonalds in our town :( but i‚Äôd say burgers \n",
            "\n",
            "@Cranky_00 Stipend isn't a salary :( 4000 kay to main burger kha jati thi üòÇ.\n",
            "First salary should have been 15k but‚Ä¶ https://t.co/MrRr0j4wQP \n",
            "\n",
            "@Justaethan oh okay :( i have a burger üçîüçî also do you want that? \n",
            "\n",
            "When mr beast burger doesn‚Äôt have a restaurant in Spain :( \n",
            "\n",
            "@toprak_mim @oatly @MictheVegan @RyanLum In our dreams: @PatrikBaboumian \n",
            "When we wake up: \"We don't have Moving Mo‚Ä¶ https://t.co/1QXJbBHgho \n",
            "\n",
            "@ataaashi it‚Äôs so bad , they don‚Äôt have wraps / burgers / paella :( \n",
            "\n",
            "----------------------------------------------------------------------------------------------------\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**2. Researching Positive attitude tweets. Pushing to a MongoDB dbs. Looking for most frequent words. Looking for tweets with a geotag to see if we can determine where did positive attitudes come from. Listing 10 sentences where each of the most frequent words occurs to get the idea of what people are unhappy about.**"
      ],
      "metadata": {
        "id": "cQG8PjRVYlTY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Positive attitudes\n",
        "query2 = 'burger OR burgers :) -filter:retweets'\n",
        "\n",
        "data2 = twitter_api.search.tweets(q=query2, lang='en', count=100)\n",
        "\n",
        "min_id = data2['statuses'][-1]['id']\n",
        "for i in range(10):\n",
        "    tweets = twitter_api.search.tweets(q=query2, lang='en', max_id=min_id, count=100)\n",
        "    min_id = tweets['statuses'][-1]['id']\n",
        "    data2['statuses'] += tweets['statuses']\n",
        "\n",
        "statuses2 = data2['statuses']\n",
        "print(len(statuses2))\n",
        "coll_pos = db['cs2_coll_pos']\n",
        "# coll_pos.drop()\n",
        "# _ = coll_pos.insert_many(statuses2)"
      ],
      "metadata": {
        "id": "BQ0P-YVAO6lC",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9472cc63-37c6-466a-8d36-8a1598d21601"
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "404\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tweet_texts_pos = [ re.sub(r\"[^\\w\\s'#@]\", \"\", tweets['text']) for tweets in statuses2 ]\n",
        "print(tweet_texts_pos[0])\n",
        "words_pos = [ w for t in tweet_texts_pos for w in t.lower().split() ]\n",
        "words_pos = list(filter(lambda x: x not in exclude, words_pos))\n",
        "print(words_pos[1])"
      ],
      "metadata": {
        "id": "sj9YLEBLWE43",
        "outputId": "92da4f6e-da41-4435-a643-90ce2357a388",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "What are your favourite foods  Meatballs burger chicken katsu sweet and sour chicken I have too many haha but httpstcoK3xRAK5z5D\n",
            "foods\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "c = Counter(words_pos)\n",
        "top_words_pos = c.most_common()[:10]\n",
        "print(top_words_pos) # top 10\n",
        "\n",
        "pt = PrettyTable(field_names=['Word', 'Count'])\n",
        "[ pt.add_row(kv) for kv in c.most_common()[:10] ]\n",
        "pt.align['Word'], pt.align['Count'] = 'l', 'r'\n",
        "print(pt)"
      ],
      "metadata": {
        "id": "KAhY3xHFWLee",
        "outputId": "ab77f78a-800e-46ca-a341-1f7453434421",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[('burger', 244), ('burgers', 96), ('good', 33), ('get', 32), ('have', 30), ('like', 29), ('king', 28), ('just', 28), ('mob', 24), ('think', 22)]\n",
            "+---------+-------+\n",
            "| Word    | Count |\n",
            "+---------+-------+\n",
            "| burger  |   244 |\n",
            "| burgers |    96 |\n",
            "| good    |    33 |\n",
            "| get     |    32 |\n",
            "| have    |    30 |\n",
            "| like    |    29 |\n",
            "| king    |    28 |\n",
            "| just    |    28 |\n",
            "| mob     |    24 |\n",
            "| think   |    22 |\n",
            "+---------+-------+\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# similar attempt to find positive \"burger\" tweets with a geotag\n",
        "query_pos1 = { \"geo\": { \"$ne\": None } }\n",
        "cursor = coll_pos.find(query_pos1)\n",
        "\n",
        "for tweet in cursor:\n",
        "    print(tweet['text'])"
      ],
      "metadata": {
        "id": "sl8ELQL8Shtv"
      },
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for combo in top_words_pos:\n",
        "    print(combo[0])\n",
        "    query = { \"text\": { '$regex': '^.*'+ combo[0] + '.*$', '$options': 'si' } }\n",
        "    cursor = coll_pos.find(query)\n",
        "    i = 0\n",
        "    # Printing first 10 tweets\n",
        "    for tweet in cursor:\n",
        "        if tweet['text'] in printed:\n",
        "            continue\n",
        "        if i >= 10:\n",
        "            break\n",
        "        print(tweet['text'], '\\n')\n",
        "        printed.append(tweet['text'])\n",
        "        i += 1\n",
        "\n",
        "    print(\"-\"*100)"
      ],
      "metadata": {
        "id": "kP1YxDCicvgK",
        "outputId": "549002db-7e39-49dd-bdcc-56bc8a0707d3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "burger\n",
            "@ishyungshi fries and burger po from mcdo ate :) \n",
            "\n",
            "@billbison77 Sounds nice :) I‚Äôll take w burger and if you need help with website i can help you build one with a takeout option üòç‚úåÔ∏è \n",
            "\n",
            "@cooolona hi po :)) i want a burger \n",
            "\n",
            "@kayla_eilhart Uhh. @McDonalds - Make a special burger without onion, so this lady can order anonymously next time‚Ä¶ https://t.co/Xka28HxJdC \n",
            "\n",
            "shout out to whoever put the veggie burger advert right after the \"eat meat and dairy :-)\" advert on ITV1 \n",
            "\n",
            "@TRIANGLE_MUPPET burger :) \n",
            "\n",
            "woul you rather eat pizza or ham burger :) https://t.co/tnGo3fReRH \n",
            "\n",
            "@Burger_Baron But don't tell him Greyhound is out of business right? :D \n",
            "\n",
            "@xdocvibez yes! burgers &amp; chicken tenders :) \n",
            "\n",
            "burger time :) \n",
            "\n",
            "----------------------------------------------------------------------------------------------------\n",
            "burgers\n",
            "@KuraiKiti This inspires hope for all burgers :) \n",
            "\n",
            "Follow for follow Burgers! Help you fellow burgers reach one hundred followers :D \n",
            "\n",
            "#TeamSehamOnKumu #KumuPh https://t.co/OG3uS6bWUa \n",
            "\n",
            "@1kebret over-sauced burgers deserve their own thread! :) \n",
            "\n",
            "@itsmeishmi Bread, cheese , meat and sweets :) not to fond of veggies . She has yet to try burgers but if she does‚Ä¶ https://t.co/Q0BQCMqnxo \n",
            "\n",
            "@Bowl_of_Worcel What episode? Bobs burgers is my comfort show and when I accidentally ate 8x the amount of gummies‚Ä¶ https://t.co/YJttuqDGJr \n",
            "\n",
            "@mrrobotoNFT done burgers :) \n",
            "\n",
            "@Overthehillprop Our local chippy. They prepare everything from scratch - mince the burgers from a cut of beef, mak‚Ä¶ https://t.co/vwSHFASKZU \n",
            "\n",
            "I'm afraid people will judge me so I order my sandwiches and burgers with lettuce only to take it off before I eat it. :) \n",
            "\n",
            "@Hardcorehayleee @/burgers.and.burpees :) \n",
            "\n",
            "@Caithlin_mully they‚Äôre by far the best vegetarian burgers i‚Äôve found, i‚Äôd recommend them to anyone :) \n",
            "\n",
            "----------------------------------------------------------------------------------------------------\n",
            "good\n",
            "btw, hoshi's burger pic looks so good and i'm currently fasting :)))))) \n",
            "\n",
            "@calpicostrawb currently comforting is murderville a new will arnett show :) bob's burgers is always a good choice \n",
            "\n",
            "@BT_BlackThunder Hey everyone, come check out my Dying Light 2 Let‚Äôs Play on PS5! I‚Äôm currently taking a good burge‚Ä¶ https://t.co/v1dt0NEhHe \n",
            "\n",
            "The way a good burger cheers you up :) \n",
            "\n",
            "went out by myself today. 2 malls, no way home, burger king, 2 sticks :))) feeling good good :))) haven't done this in awhile :))) \n",
            "\n",
            "Today was a good day\n",
            "- Got to use a power tool (immediate 7/10)\n",
            "- Ate at my fav fast food burger place for lunch (I‚Ä¶ https://t.co/GgGABqhbzG \n",
            "\n",
            "@mitchblevins To answer her question, sort of, give her a Tucker's onion burger. Looks and tastes like meat because it is meat. So good. :P \n",
            "\n",
            "@MarkCalc In fairness, you were eating. A burger :-)\n",
            "\n",
            "Your very good Open podcast somewhat blunted my memory. I sen‚Ä¶ https://t.co/Elyt1smQbT \n",
            "\n",
            "@fromthebunkerjr @ChewsViews @frangeladuo But are they as good as the Impossible burger from Burger King though? We‚Ä¶ https://t.co/3UXe8te3K6 \n",
            "\n",
            "@FanIroha Neat! :D\n",
            "I don't like burgers [unpatriotic I know! :(], but pickles and ketchup (and even cheese) are good! :) \n",
            "\n",
            "----------------------------------------------------------------------------------------------------\n",
            "get\n",
            "And the ‚ÄúeMplOyeRs sHoUld pAy yOu mOrE‚Äù argument is fucking stupid. If my employer paid me what I should be getting‚Ä¶ https://t.co/VPxFkiPAy6 \n",
            "\n",
            "Eating a butter burger to get out of my feelings :) \n",
            "\n",
            "walked 3 blocks to get pan dulce and they had none :))))))))) had to come back in the rain also üíØüíØüíØüíØ \n",
            "\n",
            "@breakcorefan420 @gum_mp3 Hahaha I remember calling in sick the day after getting Arby‚Äôs MEAT MOUNTAIN :p I‚Äôm scare‚Ä¶ https://t.co/5wfWtsuD4M \n",
            "\n",
            "@Saskgal80 @MarkEllison06 Lol! Well she said she wanted s burger mail and meant burger meal so I didn‚Äôt get the fries and she was mad :) \n",
            "\n",
            "@CheekyVic Just get a non cheese burger üçî u are an intelligent girl don't panic!!!!:) \n",
            "\n",
            "@Kitsune__Spirit i wish for vegetarian burger :) \n",
            "\n",
            "okay  guys  guys  im  going  to  burger  king  w  my  friends  after  my  exam  what  do  i  get  ??  i  get  to  l‚Ä¶ https://t.co/iS3586e9Gx \n",
            "\n",
            "@_dawnw81 @GordonRamsay Hehe right on :) just curious...what'd ya get? Burger, I presume? \n",
            "\n",
            "Drinking hot chocolate, waiting for my train. Gonna get veggie burgers with Mandy and Dylan :) \n",
            "\n",
            "----------------------------------------------------------------------------------------------------\n",
            "have\n",
            "YOUTUBE!! HUH HUH i fell scroll serious :) recome a burger May i can you like literally everything in - finished do have \n",
            "\n",
            "üåô do you have favorite brand that you like to eat?\n",
            "\n",
            "üê±: In &amp; Out Burger Jalapeno's a lot :))\n",
            "\n",
            "#Î†àÏù¥Î∏ê #oneus https://t.co/6zKzV4c87t \n",
            "\n",
            "I only ever go to burger king for impossible burgers I'm so happy to finally have options even if it's minor :) \n",
            "\n",
            "@absomarvilla You also don‚Äôt have a clue on how to spell my name! That said, when it comes to the #impossibleburger‚Ä¶ https://t.co/Lcy5F3o6lv \n",
            "\n",
            "@radiodreading And now I want a burger, dammit. :) No, I have no clue and I will finish the manga before I dare put‚Ä¶ https://t.co/PQuUvMJnp2 \n",
            "\n",
            "@freshhmeatz @paradigmnft_ Negative. We only  have Burger King and McDonalds. :D \n",
            "\n",
            "@So_Ethereal Is like they use toast ü§î\n",
            "I have tested burger on toast b4 it is cool :) \n",
            "\n",
            "i have sudden plans to meet my friends today! first time after almost 2 years! I'm so glad I've only had a glass of‚Ä¶ https://t.co/gxYA8YTYEK \n",
            "\n",
            "I can't wait to eat these. Since I can't have pickles anymore, these will go on my burgers. :) https://t.co/VXtXUBKeW1 \n",
            "\n",
            "@banditocarly HIII this is my oc guy I made him very recently so I don‚Äôt rlly have that many drawings for him and I‚Ä¶ https://t.co/84hKiq3WGu \n",
            "\n",
            "----------------------------------------------------------------------------------------------------\n",
            "like\n",
            "also i‚Äôd like to say that hungry jacks is australian burger king :) \n",
            "\n",
            "@tlrpclock when something like, annoying happens, you can always say \"not this\"! its basically the same as \"this su‚Ä¶ https://t.co/PsK5xAp9wD \n",
            "\n",
            "I've been craving for sandwich/burger na homemade for like weeks na :))))) \n",
            "\n",
            "I saw a toy set that featured the Iron Man 3 IM suit and Happy Hogan and i was just like:\n",
            "\n",
            "\"Nah screw Iron man, i want Ham Burger Man :)\" \n",
            "\n",
            "@piyushchaudhry Then it would look like child of Pizza and Burger :) \n",
            "\n",
            "@burger_crypto @BitCannaGlobal calculated if you put 3000$ in bcna osmo you will receive like 1$ per day.  Bcna is‚Ä¶ https://t.co/rUpl08UbYH \n",
            "\n",
            "@DrewNoles Like a signature burger :) x \n",
            "\n",
            "@YeetZmeN @Ghost_Burger @Wario64 it's a farming game like stardew valley :) \n",
            "\n",
            "Varsity Dream! \n",
            "He's eating a Dream burger &gt;:D \n",
            ".\n",
            "-retweets,likes,comments are cool-\n",
            "#dreamfanart #mcyt #smiletwt https://t.co/lNoClg5A9t \n",
            "\n",
            "@wnhyklvr ooh, yummy i like burgers hope u enjoy them then :D \n",
            "\n",
            "----------------------------------------------------------------------------------------------------\n",
            "king\n",
            "@georgeonthecob OH SORRY In my family we call dinner tea for some reason but we‚Äôre cooking burgers :D \n",
            "\n",
            "@almeidamarcell Burger King :) \n",
            "\n",
            "McDonalds o Burger King? :D \n",
            "\n",
            "on a second floor of a mang inasal alone eating burger king :)) https://t.co/c1bgDMLrr4 \n",
            "\n",
            "@IrlClefairy I GOT BURGER KING AND YES THIS WAS JANE INSPIRED!!! :D \n",
            "\n",
            "I didn‚Äôt hit the curb at Burger King today :)) the iced coffees are the best everüò≠ \n",
            "\n",
            "@Sammyland6 I also love the old Burger King logo :) \n",
            "\n",
            "@MinishiFox Yeah Burger King has those :D \n",
            "\n",
            "@LacrimosaDeMag Burger king XDDD Sorry.... I just can't stop eating those damn cheese balls. I don't even care abou‚Ä¶ https://t.co/svZVHuNcbk \n",
            "\n",
            "@ChefGruel That‚Äôs awesome! Well done! And keep making those burgers! I am going to travel all the way to you one of these days for one. :) \n",
            "\n",
            "----------------------------------------------------------------------------------------------------\n",
            "just\n",
            "@vegankitdotcom @zoltaire_ That's cool :) I just had a cheese burger. Non vegan, of course. \n",
            "\n",
            "@DoubleWideCap That's a $20 burger... just saying :) \n",
            "\n",
            "@themachine_07 Sameee. Was just kidding about that burger thing :p \n",
            "\n",
            "Going to do a Just Chatting cooking stream tonight! We're making BURGERS! üçî Hoping to start around 8! (Have to go b‚Ä¶ https://t.co/oi6msv8Sb2 \n",
            "\n",
            "@sanjisoup omg I'm so sorry to burger I did him an injustice, hes also a very cute worm :) \n",
            "\n",
            "----------------------------------------------------------------------------------------------------\n",
            "mob\n",
            "----------------------------------------------------------------------------------------------------\n",
            "think\n",
            "@Etown22 Thinking about that fish/burger combo :-) https://t.co/btRY3iyRhH \n",
            "\n",
            "I think tonight I'll Lab burger dad :) \n",
            "\n",
            "----------------------------------------------------------------------------------------------------\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**3. Finding 20 most popular retweeted tweets and 20 most liked tweets from positive attitude tweets. Looking for overlaps in who these people follow. Listing these accounts as primary contacts for targeted advertisement.**"
      ],
      "metadata": {
        "id": "_gx541IUY7bl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "tweets = [\n",
        "          (pop_tweet['retweet_count'], \n",
        "             pop_tweet['user']['screen_name'],\n",
        "             pop_tweet['text'])\n",
        "          for pop_tweet in statuses2\n",
        "            if 'retweeted_status' not in pop_tweet\n",
        "]\n",
        "pt = PrettyTable(field_names=['RT Count', 'Screen Name', 'Text'])\n",
        "[ pt.add_row(row) for row in sorted(tweets, reverse=True)[:20] ]\n",
        "pt.max_width['Text'] = 50\n",
        "pt.align= 'l'\n",
        "print(pt)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7O6E-MROZz7K",
        "outputId": "15077150-5593-49cb-ad6b-83bb7c4d43f1"
      },
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+----------+-----------------+----------------------------------------------------+\n",
            "| RT Count | Screen Name     | Text                                               |\n",
            "+----------+-----------------+----------------------------------------------------+\n",
            "| 30       | trioart412      | Cutie Girl Eat Burger ! :D                         |\n",
            "|          |                 |                                                    |\n",
            "|          |                 | Gift for @BellflowerBlu https://t.co/wwox3GPkmM    |\n",
            "| 23       | tanodniseham    | solid seham burgers, don‚Äôt forget to continue      |\n",
            "|          |                 | saving your coins. we still don‚Äôt know when will   |\n",
            "|          |                 | seham be nominated.‚Ä¶ https://t.co/UutMHLJ5Hv       |\n",
            "| 21       | SNLSABRINA      | i need more snl and sitcom moots. so if you like   |\n",
            "|          |                 | snl, b99, abbott elementary, new girl, modern      |\n",
            "|          |                 | family, superstore,‚Ä¶ https://t.co/ImIzYQuFmb       |\n",
            "| 15       | SehamDaghlasWW  | Good afternoon burgers. Pls use team ZacHam        |\n",
            "|          |                 | official tagline :)                                |\n",
            "|          |                 |                                                    |\n",
            "|          |                 | FRIDATE WITH ZACHAM                                |\n",
            "| 14       | TEAMSEHAMOFC    | Expect nothing prepare for the worst. If you       |\n",
            "|          |                 | didn‚Äôt know, Team Seham has a Donation Drive set   |\n",
            "|          |                 | up. Rest assured that‚Ä¶ https://t.co/wZLNan0bHS     |\n",
            "| 8        | SehamDaghlasWW  | Good morning burgers :)                            |\n",
            "|          |                 |                                                    |\n",
            "|          |                 | #TeamSehamOnKumu                                   |\n",
            "|          |                 | #KumuPh https://t.co/JklMxgQXrL                    |\n",
            "| 8        | SehamDaghlasWW  | Drop your self love affirmations burgers. As many  |\n",
            "|          |                 | as you want :)                                     |\n",
            "|          |                 | #TeamSehamOnKumu                                   |\n",
            "|          |                 | #kumuPh https://t.co/2SfyGUt41A                    |\n",
            "| 7        | mochijapa       | üëÜAn useful expression related to the above        |\n",
            "|          |                 |                                                    |\n",
            "|          |                 | ‚úÖXÊ¥æ=X ha= X person                               |\n",
            "|          |                 |                                                    |\n",
            "|          |                 | Use XÊ¥æ when you want to say ‚ÄúI prefer X than      |\n",
            "|          |                 | compet‚Ä¶ https://t.co/SmgzfY0YnA                    |\n",
            "| 6        | trioart412      | Yummy Burger king :) https://t.co/WTV6EBMx0F       |\n",
            "| 6        | gnfdreaming     | hi @MrBeast.                                       |\n",
            "|          |                 |                                                    |\n",
            "|          |                 | hi my friend  @dreamwastaken loves Beast Burgers,  |\n",
            "|          |                 | games, youtube and money ! he's streaming rn on‚Ä¶   |\n",
            "|          |                 | https://t.co/GICpR9HEb1                            |\n",
            "| 6        | SehamDaghlasWW  | Last engagement booster for today's tp. Patulan    |\n",
            "|          |                 | nyo na to burgers :)                               |\n",
            "|          |                 |                                                    |\n",
            "|          |                 | LigTask SiSeham                                    |\n",
            "|          |                 | #PBBAdult3rdNomi https://t.co/6fQgndB464           |\n",
            "| 5        | iamMrZia        | Let's confuse Burgers :p https://t.co/SunLzvtEgk   |\n",
            "| 5        | TEAMSEHAMOFC    | Lets start building our Voting Team Burgers! DM if |\n",
            "|          |                 | you‚Äôre willing to join a committed voting team for |\n",
            "|          |                 | Seham :D                                           |\n",
            "|          |                 |                                                    |\n",
            "|          |                 | SA‚Ä¶ https://t.co/aF0BQJI5Ey                        |\n",
            "| 4        | bbyxminie       | skeppy jr going to gloop gloop burgers :D          |\n",
            "|          |                 |                                                    |\n",
            "|          |                 | this isn‚Äôt my c! charlie design i forgot what i    |\n",
            "|          |                 | made mine D: https://t.co/yVW0XJ7OuJ               |\n",
            "| 3        | zachupido       | kaya natin 'to Cookies, Charmers, and Burgers.     |\n",
            "|          |                 | Tweet lang ng tweet! :)                            |\n",
            "|          |                 |                                                    |\n",
            "|          |                 | FRIDATE WITH ZACHAM                                |\n",
            "|          |                 | #PBBInTheNameOfLove https://t.co/xNV6qES15l        |\n",
            "| 3        | zachupido       | kaya natin 'to Cookies, Charmers, and Burgers.     |\n",
            "|          |                 | Tweet lang ng tweet! :)                            |\n",
            "|          |                 |                                                    |\n",
            "|          |                 | FRIDATE WITH ZACHAM                                |\n",
            "|          |                 | #PBBInTheNameOfLove https://t.co/xNV6qES15l        |\n",
            "| 3        | TEAMSEHAMOFC    | Follow for follow Burgers! Help you fellow burgers |\n",
            "|          |                 | reach one hundred followers :D                     |\n",
            "|          |                 |                                                    |\n",
            "|          |                 | #TeamSehamOnKumu #KumuPh https://t.co/OG3uS6bWUa   |\n",
            "| 3        | HelenJRaine     | @mikesharman It was for @OneMinuteBriefs. Here are |\n",
            "|          |                 | the other winning submissions :) the Burger King   |\n",
            "|          |                 | one is also fli‚Ä¶ https://t.co/An6YE9lGOp           |\n",
            "| 2        | YellingMadman   | This lil dude dreams about burgers just as much as |\n",
            "|          |                 | me, we're gonna get along just fine :)             |\n",
            "|          |                 | https://t.co/oK9FfnK77z                            |\n",
            "| 1        | tomhunternelson | Q: Your burgers started tasting a little different |\n",
            "|          |                 | to me in 2018. Am I going nuts?                    |\n",
            "|          |                 | A: Relax, you‚Äôre not nuts! :) In‚Ä¶                  |\n",
            "|          |                 | https://t.co/QDIKqnR1kI                            |\n",
            "+----------+-----------------+----------------------------------------------------+\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tweets = [\n",
        "          (pop_tweet['favorite_count'], \n",
        "             pop_tweet['user']['screen_name'],\n",
        "             pop_tweet['text'])\n",
        "          for pop_tweet in statuses2\n",
        "            if 'retweeted_status' not in pop_tweet\n",
        "]\n",
        "pt = PrettyTable(field_names=['Likes Count', 'Screen Name', 'Text'])\n",
        "[ pt.add_row(row) for row in sorted(tweets, reverse=True)[:20] ]\n",
        "pt.max_width['Text'] = 50\n",
        "pt.align= 'l'\n",
        "print(pt)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5tdLg2M5dB8G",
        "outputId": "7fcaef15-457c-4930-f420-15cc79a37e6c"
      },
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-------------+-----------------+----------------------------------------------------+\n",
            "| Likes Count | Screen Name     | Text                                               |\n",
            "+-------------+-----------------+----------------------------------------------------+\n",
            "| 188         | trioart412      | Cutie Girl Eat Burger ! :D                         |\n",
            "|             |                 |                                                    |\n",
            "|             |                 | Gift for @BellflowerBlu https://t.co/wwox3GPkmM    |\n",
            "| 140         | SNLSABRINA      | i need more snl and sitcom moots. so if you like   |\n",
            "|             |                 | snl, b99, abbott elementary, new girl, modern      |\n",
            "|             |                 | family, superstore,‚Ä¶ https://t.co/ImIzYQuFmb       |\n",
            "| 128         | Osiefish        | I gonna move my Geoguessr stream to 4 o‚Äôclock :) I |\n",
            "|             |                 | need burger                                        |\n",
            "| 99          | paricyte        | @meowriza thank you for your support on us burgers |\n",
            "|             |                 | meowriza :D                                        |\n",
            "| 74          | trioart412      | Yummy Burger king :) https://t.co/WTV6EBMx0F       |\n",
            "| 69          | bbyxminie       | skeppy jr going to gloop gloop burgers :D          |\n",
            "|             |                 |                                                    |\n",
            "|             |                 | this isn‚Äôt my c! charlie design i forgot what i    |\n",
            "|             |                 | made mine D: https://t.co/yVW0XJ7OuJ               |\n",
            "| 44          | gnfdreaming     | hi @MrBeast.                                       |\n",
            "|             |                 |                                                    |\n",
            "|             |                 | hi my friend  @dreamwastaken loves Beast Burgers,  |\n",
            "|             |                 | games, youtube and money ! he's streaming rn on‚Ä¶   |\n",
            "|             |                 | https://t.co/GICpR9HEb1                            |\n",
            "| 40          | tanodniseham    | solid seham burgers, don‚Äôt forget to continue      |\n",
            "|             |                 | saving your coins. we still don‚Äôt know when will   |\n",
            "|             |                 | seham be nominated.‚Ä¶ https://t.co/UutMHLJ5Hv       |\n",
            "| 33          | BillyStevens999 | I‚Äôm in LA and I just drove past an in and out      |\n",
            "|             |                 | burger and I‚Äôve never seen one before so it made   |\n",
            "|             |                 | me really really happy :)))                        |\n",
            "| 27          | mochijapa       | üëÜAn useful expression related to the above        |\n",
            "|             |                 |                                                    |\n",
            "|             |                 | ‚úÖXÊ¥æ=X ha= X person                               |\n",
            "|             |                 |                                                    |\n",
            "|             |                 | Use XÊ¥æ when you want to say ‚ÄúI prefer X than      |\n",
            "|             |                 | compet‚Ä¶ https://t.co/SmgzfY0YnA                    |\n",
            "| 22          | iamMrZia        | Let's confuse Burgers :p https://t.co/SunLzvtEgk   |\n",
            "| 15          | ChanelMurder    | making turkey burgers and fries :-)                |\n",
            "| 14          | R0ninTheWolf    | *puts you on a Burger King crown*                  |\n",
            "|             |                 | You are now da queen/king of burgers!! :D          |\n",
            "| 13          | miskaknapek     | @mjtech01 @guido_burger @Philips Crypto mining in  |\n",
            "|             |                 | your toothbrush :-)                                |\n",
            "| 12          | mercutiokin     | made burgers tonight. dressed with blueberry jam   |\n",
            "|             |                 | goat cheese arugula &gt;:)                         |\n",
            "| 12          | YellingMadman   | This lil dude dreams about burgers just as much as |\n",
            "|             |                 | me, we're gonna get along just fine :)             |\n",
            "|             |                 | https://t.co/oK9FfnK77z                            |\n",
            "| 11          | friesforBrice   | went out by myself today. 2 malls, no way home,    |\n",
            "|             |                 | burger king, 2 sticks :))) feeling good good :)))  |\n",
            "|             |                 | haven't done this in awhile :)))                   |\n",
            "| 11          | TEAMSEHAMOFC    | Expect nothing prepare for the worst. If you       |\n",
            "|             |                 | didn‚Äôt know, Team Seham has a Donation Drive set   |\n",
            "|             |                 | up. Rest assured that‚Ä¶ https://t.co/wZLNan0bHS     |\n",
            "| 11          | SehamDaghlasWW  | Good morning burgers :)                            |\n",
            "|             |                 |                                                    |\n",
            "|             |                 | #TeamSehamOnKumu                                   |\n",
            "|             |                 | #KumuPh https://t.co/JklMxgQXrL                    |\n",
            "| 10          | lowpolyburgers  | mottourisart was cause my old gamer name was       |\n",
            "|             |                 | mottouri (doesn't mean anything, was just a random |\n",
            "|             |                 | word) and :) 's art‚Ä¶ https://t.co/hy8L3hC21M       |\n",
            "+-------------+-----------------+----------------------------------------------------+\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Unfortunately, upon closer examination of most liked and retweeted accounts that are related to burgers, we decided that this may be a poor tactic for determining accounts for advertisement. Unfortunately, most liked and most retweeted tweets that contain the word burger, are often related to something other than a burger."
      ],
      "metadata": {
        "id": "lHFjuJ1EdeZi"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tD6h0TglY6Dv"
      },
      "source": [
        "*-----------------\n",
        "# Done\n",
        "\n",
        "All set! \n",
        "\n",
        "** What do you need to submit?**\n",
        "\n",
        "* **Notebook File**: Save this IPython notebook, and find the notebook file in your folder (for example, \"filename.ipynb\"). This is the file you need to submit. Please make sure all the plotted tables and figures are in the notebook. If you used \"ipython notebook --pylab=inline\" to open the notebook, all the figures and tables should have shown up in the notebook.\n",
        "\n",
        "\n",
        "* **PPT Slides**: please prepare PPT slides (for 15 minutes' talk) to present about the case study . We will ask *all* teams to present their case studies in class for this case study. \n",
        "\n",
        "* **Report**: please prepare a report (less than 10 pages) to report what you found in the data.\n",
        "    * What data you collected? \n",
        "    * Why this topic is interesting or important to you? (Motivations)\n",
        "    * How did you analyse the data?\n",
        "    * What did you find in the data? \n",
        " \n",
        "     (please include figures or tables in the report, but no source code)\n",
        "\n",
        "Please compress all the files in a zipped file.\n",
        "\n",
        "\n",
        "** How to submit: **\n",
        "\n",
        "        Please submit through canvas.wpi.edu\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-FvDoMzSY6Dv"
      },
      "source": [
        "# Grading Criteria:\n",
        "\n",
        "**Totoal Points: 100**\n",
        "\n",
        "\n",
        "---------------------------------------------------------------------------\n",
        "**Notebook results:**\n",
        "    Points: 80\n",
        "\n",
        "\n",
        "    -----------------------------------\n",
        "    Question 1:\n",
        "    Points: 20\n",
        "    -----------------------------------\n",
        "    \n",
        "    -----------------------------------\n",
        "    Question 2:\n",
        "    Points: 20\n",
        "    -----------------------------------\n",
        "        \n",
        "    -----------------------------------\n",
        "    Question 3:\n",
        "    Points: 20\n",
        "    -----------------------------------\n",
        "  \n",
        "    -----------------------------------\n",
        "    Question 4:  Business question\n",
        "    Points: 20\n",
        "    -----------------------------------\n",
        "\n",
        "\n",
        "---------------------------------------------------------------------------\n",
        "**Slides (for 5-10 minutes of presentation): Story-telling**\n",
        "    Points: 20\n",
        "\n",
        "\n",
        "1. Motivation about the data collection, why the topic is interesting to you.\n",
        "    Points: 5 \n",
        "\n",
        "2. Communicating Results (figure/table)\n",
        "    Points: 10 \n",
        "\n",
        "3. Story telling (How all the parts (data, analysis, result) fit together as a story?)\n",
        "    Points: 5 \n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "metadata": {
        "id": "2Wy1xam0Y6Dw"
      },
      "outputs": [],
      "source": [
        ""
      ]
    }
  ],
  "metadata": {
    "anaconda-cloud": {},
    "kernel_info": {
      "name": "python3"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.5"
    },
    "nteract": {
      "version": "0.2.0"
    },
    "colab": {
      "name": "CaseStudy2_MongoDB.ipynb",
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}